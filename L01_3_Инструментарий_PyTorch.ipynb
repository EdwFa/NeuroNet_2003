{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdwFa/NeuroNet_2003/blob/main/L01_3_%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D1%80%D0%B8%D0%B9_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGF7kjy76P6x"
      },
      "source": [
        " <font size=\"6\">Лекция_1.Введение в нейронные сети (часть3)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK1USFLV6P7U"
      },
      "source": [
        "#### Введение в PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEc5G1A6P7U"
      },
      "source": [
        "Практически вся наша работа с этого момента будет осуществляться с помощью [PyTorch](https://pytorch.org/), поэтому необходимо познакомиться с основными концептами, принципами и функциями PyTorch.\n",
        "\n",
        "Лучший друг в этом, конечно же, [документация](https://pytorch.org/docs/stable/index.html), однако можно привести основные моменты этой библиотеки/фреймворка:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a61cPJ3D6P7U"
      },
      "source": [
        "##### Основная сущность — torch.Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWCSbRKo6P7U"
      },
      "source": [
        "Поскольку основная сущность, с которой мы работаем, это вектора и матрицы, то для них нужен очень мощный и функциональный класс — [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch.Tensor)\n",
        "\n",
        "Создание \"пустого\" тензора:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jk4sr1zD6P7V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "a = torch.Tensor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpynVe7e6P7V"
      },
      "source": [
        "Конструктор класса с заполнением существующими значениями:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3zK-c8R6P7V",
        "outputId": "5886a649-3ddc-4cb9-dbd4-59d511b068bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "a = torch.tensor([1.1, 2.2, 3.2])\n",
        "a.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx2kN0Tv6P7V"
      },
      "source": [
        "Явное указание типа данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIZJ4D6g6P7V",
        "outputId": "42fa924e-39b4-4d5a-ad21-836b0134a3f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "a = torch.tensor([1.1, 2.2, 3.2], dtype=torch.float64)\n",
        "a.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfuuyv-H6P7W"
      },
      "source": [
        "Создание 2-мерного тензора, заполненного единицами (для нулей zeros)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AsxQlEB6P7W",
        "outputId": "127b523e-c1a1-4a05-e952-0a759d79d1d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "a = torch.ones(size=(3, 2))\n",
        "a.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB-OJxDs6P7W"
      },
      "source": [
        "Создание 2-мерного тензора, заполненного указанным значением\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sccs4Mcd6P7W",
        "outputId": "6db8e58e-8e25-43b4-c119-c995423d3b77"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.1000, 5.1000],\n",
              "        [5.1000, 5.1000],\n",
              "        [5.1000, 5.1000]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "a = torch.full((3, 2), 5.1)\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se9sHCul6P7W"
      },
      "source": [
        "Транспонирование (изменение порядка осей)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj9NtQK_6P7W",
        "outputId": "79e66be2-a7c8-4d4e-baa8-0d78c298fe01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.1000, 5.1000, 5.1000],\n",
              "        [5.1000, 5.1000, 5.1000]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "a = a.T\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSovjWWw6P7W"
      },
      "source": [
        "В библиотеке доступно огромное количество встроенных математических примитивов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osd04rSS6P7X",
        "outputId": "77626755-a322-4715-f22f-e51acc3b24b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7854, 0.7854, 0.7854])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "c = torch.atan2(a[0], a[1])\n",
        "c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQXSvgMK6P7X"
      },
      "source": [
        "Почти всё, что есть в NumPy, есть в PyTorch, например, `sum()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Dofygv46P7X",
        "outputId": "e3d1f72b-7987-4a9b-d7e7-5c18909ed0f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3562)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "c.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbcQBwKv6P7X"
      },
      "source": [
        "Перестановка, удаление и добавление пространственных измерений:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lrwf1Iui6P7Y",
        "outputId": "5e90afb4-4b48-4440-e3a5-6588f207bd3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor size:\n",
            " torch.Size([2, 5, 1, 8])\n",
            "After permute tensor size:\n",
            " torch.Size([1, 2, 8, 5])\n",
            "After squzee tensor size:\n",
            " torch.Size([2, 8, 5])\n",
            "After unsquzee tensor size:\n",
            " torch.Size([1, 2, 8, 5])\n"
          ]
        }
      ],
      "source": [
        "a = torch.zeros((2, 5, 1, 8))\n",
        "print(\"Original tensor size:\\n\", a.size())\n",
        "\n",
        "a = a.permute(dims=(2, 0, 3, 1))  # permute dimensions\n",
        "print(\"After permute tensor size:\\n\", a.size())\n",
        "\n",
        "a = a.squeeze()  # delete dimension\n",
        "print(\"After squzee tensor size:\\n\", a.size())\n",
        "\n",
        "a = a.unsqueeze(dim=0)  # add dimension\n",
        "print(\"After unsquzee tensor size:\\n\", a.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHFQtzgl6P7Y"
      },
      "source": [
        "Преобразование torch.Tensor в NumPy-массив:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfs0wW5T6P7Y",
        "outputId": "edab70df-de28-4f04-9e31-bccf37450933"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "a.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOVi4QV76P7Y"
      },
      "source": [
        "PyTorch позволяет тензору быть представлением (view) существующего тензора. Тензор представления использует те же базовые данные, что и его базовый тензор. Поддержка `view` позволяет избежать явного копирования данных, что позволяет нам выполнять быстрое и эффективное изменение формы, нарезку и операции с элементами."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z-HTg1S6P7Z",
        "outputId": "2644983e-49f3-45fa-acb1-05310c40cdf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor:\n",
            " tensor([[0.5144, 0.0526, 0.9402, 0.0610, 0.8708, 0.6226, 0.6889, 0.4427],\n",
            "        [0.2233, 0.5118, 0.2653, 0.3512, 0.2926, 0.2640, 0.0709, 0.1466]])\n",
            "Tensor after view tensor:\n",
            " tensor([[0.5144, 0.0526, 0.9402, 0.0610],\n",
            "        [0.8708, 0.6226, 0.6889, 0.4427],\n",
            "        [0.2233, 0.5118, 0.2653, 0.3512],\n",
            "        [0.2926, 0.2640, 0.0709, 0.1466]])\n",
            "Add 1 to tensor:\n",
            " tensor([[1.5144, 1.0526, 1.9402, 1.0610],\n",
            "        [1.8708, 1.6226, 1.6889, 1.4427],\n",
            "        [1.2233, 1.5118, 1.2653, 1.3512],\n",
            "        [1.2926, 1.2640, 1.0709, 1.1466]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.rand(2, 8)\n",
        "print(\"Original tensor:\\n\", a)\n",
        "b = a.view(\n",
        "    4, 4\n",
        ")  # carefully with structured data, reshape/view can transform image to unreadable view\n",
        "print(\"Tensor after view tensor:\\n\", b)\n",
        "b += 1\n",
        "print(\"Add 1 to tensor:\\n\", b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWRKDMNG6P7Z"
      },
      "source": [
        "Размещение тензора на GPU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozwe02Yw6P7Z",
        "outputId": "39c85a13-11f9-4264-dce5-42857dbb16c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda available:  False \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.0288, 2.1051, 3.8805, 2.1220, 3.7416, 3.2451, 3.3777, 2.8854],\n",
              "        [2.4466, 3.0235, 2.5306, 2.7025, 2.5853, 2.5280, 2.1418, 2.2931]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Cuda available: \", torch.cuda.is_available(), \"\\n\")\n",
        "a = a.to(device)  # tensor to gpu\n",
        "b = torch.full_like(a, 2).to(device)\n",
        "c = a * b  # compute on gpu (more fast with parallel computing)\n",
        "c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHwSNCcQ6P7Z"
      },
      "source": [
        "##### Автоматическое вычисление градиентов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egj6_pq76P7Z"
      },
      "source": [
        "PyTorch умеет запоминать последовательность операций с нашими тензорами и вычислять градиент."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFA8R4yY6P7a",
        "outputId": "0a3462a7-fe87-447a-d188-58fbb2e8c250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W.grad = None (before forward pass must be 'None')\n",
            "MSE = 7.5\n",
            "W.grad = -15.0\n"
          ]
        }
      ],
      "source": [
        "x_train = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
        "y_train = torch.tensor([2.0, 4.0, 6.0, 8.0])\n",
        "\n",
        "W = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "print(f\"W.grad = {W.grad} (before forward pass must be 'None')\")\n",
        "\n",
        "y_pred = W * x_train\n",
        "criterion = torch.nn.MSELoss()\n",
        "MSE = criterion(y_pred, y_train)\n",
        "print(f\"MSE = {MSE}\")\n",
        "\n",
        "# backward pass to compute gradient dMSE/dw\n",
        "MSE.backward()\n",
        "print(f\"W.grad = {W.grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5igwsQ846P7a"
      },
      "source": [
        "Отсоединение тензора от графа вычислений (используйте при копировании тензора):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWLur9gU6P7a",
        "outputId": "203e3672-2b58-4ecb-91a5-6bc928456a33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "W.detach()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCqUzUOP6P7a"
      },
      "source": [
        "##### Другие интересные подмодули фреймворка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyR3PkBk6P7a"
      },
      "source": [
        "\n",
        "Torch\n",
        "\n",
        "* ```torch.nn``` — модуль для работы с нейронными сетями в стиле ООП\n",
        "* ```torch.nn.functional``` — то же, что выше, но в функциональном стиле\n",
        "* ```torch.utils.data``` — создание датасета, даталоадера\n",
        "* ```torch.linalg``` — линейная алгебра\n",
        "* ```torch.fft``` — преобразования Фурье\n",
        "* ```torch.random``` — реализация функций, связанных со случайностью\n",
        "\n",
        "\n",
        "[Torchvision](https://pytorch.org/vision/stable/index.html) — работа с изображениями\n",
        "* ```torchvision.transforms``` — трансформации и предобработки для изображений\n",
        "* ```torchvision.datasets``` — учебные датасеты\n",
        "* ```torchvision.models``` — готовые модели для обработки изображений\n",
        "\n",
        "[Torchaudio](https://pytorch.org/audio/stable/index.html) — работа с аудио.\n",
        "* ```torchaudio.transforms``` — общие методы обработки звука и извлечения признаков\n",
        "* ```torchaudio.datasets``` — учебные датасеты\n",
        "* ```torchaudio.models``` — готовые модели для обработки аудио\n",
        "\n",
        "[Torchtext](https://pytorch.org/text/stable/index.html) — работа с текстом.\n",
        "* ```torchtext.transforms``` — общие методы предобработки и трансформации текста\n",
        "\n",
        "etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTha31TG6P7a"
      },
      "source": [
        "####  Backprop in PyTorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UScmelH6P7b"
      },
      "source": [
        "Рассмотрим алгоритм обратного распространения на примере вычисления квадрата ошибки для линейной регрессии (для простоты не будем рассматривать смещение):\n",
        "\n",
        "$$y=w\\cdot x, \\quad при \\;x=[1,2,3,4],\\;y=[2,4,6,8],\\;w=1$$\n",
        "\n",
        "В данном примере видно, что предсказанный моделью $\\hat{y}=[1,2,3,4]$ не совпадает с истинными значениями $y$, и, соответственно, квадратичная ошибка для такого примера будет: $$MSE=\\frac{1}{4}\\sum_{i=1}^4E_i^2=\\frac{1}{4}\\sum_{i=1}^4(\\hat{y}_i-y_i)^2=\\frac{1+4+9+16}{4}=7.5$$\n",
        "\n",
        "Градиент весов $w$ вычисляется следующим образом, в соответствии с цепным правилом:\n",
        "\n",
        "$$\\frac{d MSE}{d w} = \\frac{\\partial MSE}{\\partial E}\\cdot \\frac{\\partial E}{\\partial \\hat{y}}\\cdot \\frac{\\partial \\hat{y}}{\\partial w}$$\n",
        "\n",
        "Рассчитаем его с использованием PyTorch:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FCm0Xdi6P7b",
        "outputId": "6f6a644b-2b62-42cd-c77c-26f63ad573ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W.grad = None (before forward pass must be 'None')\n",
            "\n",
            "MSE = 7.5\n",
            "W.grad = -15.0\n",
            "E.grad = None\n"
          ]
        }
      ],
      "source": [
        "x_train = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "y_train = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "# This is the parameter we want to optimize -> requires_grad=True\n",
        "W = torch.tensor(1.0, dtype=torch.float32, requires_grad=True)\n",
        "print(f\"W.grad = {W.grad} (before forward pass must be 'None')\\n\")\n",
        "# forward pass to compute MSE\n",
        "y_pred = W * x_train\n",
        "E = y_pred - y_train\n",
        "SE = E**2\n",
        "MSE = SE.mean()\n",
        "print(f\"MSE = {MSE}\")\n",
        "\n",
        "# backward pass to compute gradient dMSE/dw\n",
        "MSE.backward()\n",
        "print(f\"W.grad = {W.grad}\")\n",
        "print(f\"E.grad = {E.retain_grad()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWZ0RpNr6P7b"
      },
      "source": [
        "В данном примере мы произвели следующие расчеты:\n",
        "\n",
        "$\\displaystyle \\frac{\\partial MSE}{\\partial E}=\\frac{\\sum\\partial E^2}{\\partial E}=\\frac{1}{4}\\cdot2\\cdot E=\\frac{1}{2}*[-1, -2, -3, -4]=[-0.5, -1, -1.5, -2]\\quad $ $*$ — поэлементное умножение\n",
        "\n",
        "$\\displaystyle \\frac{\\partial E}{\\partial \\hat{y}}=\\frac{\\partial (\\hat{y}-y)}{\\partial \\hat{y}}=1$\n",
        "\n",
        "$\\displaystyle \\frac{\\partial \\hat{y}}{\\partial w}=\\frac{\\partial wx}{\\partial w}=x=[1, 2, 3, 4]$\n",
        "\n",
        "$\\displaystyle \\frac{d MSE}{d w} = \\frac{\\partial MSE}{\\partial E}\\cdot \\frac{\\partial E}{\\partial \\hat{y}}\\cdot \\frac{\\partial \\hat{y}}{\\partial w}=\\sum[-0.5, -1, -1.5, -2]*[1, 2, 3, 4]=-0.5-2-4.5-8=-15$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GblUpNIW6P7b"
      },
      "source": [
        "`MSE.backward()` автоматически вычисляет градиент $\\large \\frac{dMSE}{dw}$ при указании `requires_grad=True`.\n",
        "Результаты вычислений будут храниться в `W.grad`. Для всех промежуточных переменных градиенты не сохраняются, поэтому попытка обратиться, например, к `E.grad` выдает `None`.\n",
        "\n",
        "Также после однократного обратного прохода в целях экономии памяти граф, используемый для вычисления градиента, будет удаляться, и следующий запуск `MSE.backward()` будет выдавать ошибку:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYP9XDgw6P7b"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "MSE.backward() # Error on second backward call\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io0TBNIB6P7b"
      },
      "source": [
        "Чтобы сохранить вычислительный граф, для аргумента `retain_graph` функции `backward()` нужно указать значение `True`. Также может быть полезным сохранять значения градиентов для промежуточных переменных, это делается с помощью функции `tensor.retain_grad()`. В таком случае, значения градиентов, полученные на следующих итерациях обратного распространения ошибки, будут складываться с текущими значениями градиентов.\n",
        "\n",
        "Градиенты переменных, для которых был указан `retain_graph=True`, сохраняются автоматически. Чтобы избежать их накопления при многократном итерировании алгоритма обратного распространения, нужно обнулять градиент на каждом шаге с помощью функции `tensor.grad.zero_()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otTc5egW6P7c",
        "outputId": "2b676227-91b0-4268-ec5c-5331b508910e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Backprop 1 ==============\n",
            "dMSE/dE = tensor([-0.5000, -1.0000, -1.5000, -2.0000])\n",
            "dMSE/dW = -15.0\n",
            "========== Backprop 2 ==============\n",
            "dMSE/dE = tensor([-1., -2., -3., -4.])\n",
            "dMSE/dW = -30.0\n",
            "========== Backprop 3 ==============\n",
            "dMSE/dE = tensor([-1.5000, -3.0000, -4.5000, -6.0000])\n",
            "dMSE/dW = -15.0\n"
          ]
        }
      ],
      "source": [
        "x_train = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "y_train = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "# This is the parameter we want to optimize -> requires_grad=True\n",
        "W = torch.tensor(1.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# forward pass to compute MSE\n",
        "y_pred = W * x_train\n",
        "E = y_pred - y_train\n",
        "E.retain_grad()  # Save grads for intermediate tensor E in memory\n",
        "SE = E**2\n",
        "MSE = SE.sum().div(4)\n",
        "\n",
        "print(\"========== Backprop 1 ==============\")\n",
        "MSE.backward(retain_graph=True)\n",
        "print(f\"dMSE/dE = {E.grad}\")\n",
        "print(f\"dMSE/dW = {W.grad}\")\n",
        "\n",
        "print(\"========== Backprop 2 ==============\")\n",
        "MSE.backward(retain_graph=True)\n",
        "# Gradients are accumulated\n",
        "print(f\"dMSE/dE = {E.grad}\")\n",
        "print(f\"dMSE/dW = {W.grad}\")\n",
        "\n",
        "print(\"========== Backprop 3 ==============\")\n",
        "W.grad.zero_()  # Nullify gradients for W for the next iteration\n",
        "MSE.backward(retain_graph=True)\n",
        "# Gradients for W are not accumulated, but not for E\n",
        "print(f\"dMSE/dE = {E.grad}\")\n",
        "print(f\"dMSE/dW = {W.grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI_gHTJz6P7c"
      },
      "source": [
        "Итак, мы умеем вычислять градиент $\\large \\frac{\\partial MSE}{\\partial w}$ для нашего примера. Теперь давайте с его помощью оптимизируем веса, используя алгоритм обратного распространения ошибки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WiMpDZR6P7c",
        "outputId": "d6c79f58-f90f-43e1-fbf1-4864b8ca6f0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(x) = tensor([1., 2., 3., 4.], grad_fn=<MulBackward0>)\n",
            "True values: y = tensor([2., 4., 6., 8.])\n",
            "\n",
            "epoch 1: w = 1.144, loss = 6.41718674\n",
            "epoch 11: w = 1.608, loss = 1.34952068\n",
            "epoch 21: w = 1.820, loss = 0.28380114\n",
            "epoch 31: w = 1.917, loss = 0.05968266\n",
            "epoch 41: w = 1.962, loss = 0.01255111\n",
            "epoch 51: w = 1.983, loss = 0.00263946\n",
            "epoch 61: w = 1.992, loss = 0.00055505\n",
            "epoch 71: w = 1.996, loss = 0.00011674\n",
            "epoch 81: w = 1.998, loss = 0.00002455\n",
            "epoch 91: w = 1.999, loss = 0.00000516\n",
            "epoch 101: w = 2.000, loss = 0.00000109\n",
            "\n",
            "Prediction after training: f(x) = tensor([1.9996, 3.9993, 5.9989, 7.9986], grad_fn=<MulBackward0>)\n",
            "True values: y = tensor([2., 4., 6., 8.])\n"
          ]
        }
      ],
      "source": [
        "x_train = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "y_train = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "W = torch.tensor(1.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "\n",
        "# Define model output\n",
        "def forward(x_train):\n",
        "    return W * x_train\n",
        "\n",
        "\n",
        "# Compute MSE loss\n",
        "def criterion(y_pred, y_train):\n",
        "    return ((y_pred - y_train) ** 2).mean()\n",
        "\n",
        "\n",
        "print(f\"Prediction before training: f(x) = {forward(x_train)}\")\n",
        "print(f\"True values: y = {y_train}\\n\")\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.005\n",
        "num_epochs = 102\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Propagate forward\n",
        "    y_pred = forward(x_train)\n",
        "\n",
        "    # Compute MSE loss\n",
        "    MSE = criterion(y_pred, y_train)\n",
        "\n",
        "    # Propagate backward, compute gradients\n",
        "    MSE.backward()\n",
        "\n",
        "    # Update weights\n",
        "    with torch.no_grad():  #  We don't want this step to be the part of the computational graph\n",
        "        W -= learning_rate * W.grad\n",
        "\n",
        "    # Nullify gradients after updating to avoid their accumulation\n",
        "    W.grad.zero_()\n",
        "\n",
        "    if epoch % 10 == 1:\n",
        "        print(f\"epoch {epoch}: w = {W.item():.3f}, loss = {MSE.item():.8f}\")\n",
        "\n",
        "print(f\"\\nPrediction after training: f(x) = {forward(x_train)}\")\n",
        "print(f\"True values: y = {y_train}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scQ-KlYV6P7c"
      },
      "source": [
        "Видно, что наш подход позволяет оптимизировать вес $w$ регрессии из примера и таким образом добиться почти идеального предсказания нашей модели, однако в данном подходе дополнительно можно автоматизировать вычисление функции потерь и обновление параметров с учетом градиента, используя готовые функции потерь из `torch.nn` и оптимизаторы из `torch.optim`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp8ESb9c6P7c",
        "outputId": "55acd840-b9f0-4838-a1a5-3fbd4e221fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(x) = tensor([1., 2., 3., 4.], grad_fn=<MulBackward0>)\n",
            "True values: y = tensor([2., 4., 6., 8.])\n",
            "\n",
            "epoch 1: w = 1.144, loss = 6.41718674\n",
            "epoch 11: w = 1.608, loss = 1.34951985\n",
            "epoch 21: w = 1.820, loss = 0.28380090\n",
            "epoch 31: w = 1.917, loss = 0.05968266\n",
            "epoch 41: w = 1.962, loss = 0.01255111\n",
            "epoch 51: w = 1.983, loss = 0.00263946\n",
            "epoch 61: w = 1.992, loss = 0.00055505\n",
            "epoch 71: w = 1.996, loss = 0.00011674\n",
            "epoch 81: w = 1.998, loss = 0.00002455\n",
            "epoch 91: w = 1.999, loss = 0.00000516\n",
            "epoch 101: w = 2.000, loss = 0.00000109\n",
            "\n",
            "Prediction after training: f(x) = tensor([1.9996, 3.9993, 5.9989, 7.9986], grad_fn=<MulBackward0>)\n",
            "True values: y = tensor([2., 4., 6., 8.])\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "x_train = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "y_train = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "W = torch.tensor(1.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "\n",
        "# Define model output\n",
        "def forward(x_train):\n",
        "    return W * x_train\n",
        "\n",
        "\n",
        "print(f\"Prediction before training: f(x) = {forward(x_train)}\")\n",
        "print(f\"True values: y = {y_train}\\n\")\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.005\n",
        "num_epochs = 102\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD([W], lr=learning_rate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Propagate forward\n",
        "    y_pred = forward(x_train)\n",
        "\n",
        "    # Compute MSE loss\n",
        "    MSE = criterion(y_pred, y_train)\n",
        "\n",
        "    # Propagate backward, compute gradients\n",
        "    MSE.backward()\n",
        "\n",
        "    # Update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # Nullify gradients after updating to avoid their accumulation\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 10 == 1:\n",
        "        print(f\"epoch {epoch}: w = {W.item():.3f}, loss = {MSE.item():.8f}\")\n",
        "\n",
        "print(f\"\\nPrediction after training: f(x) = {forward(x_train)}\")\n",
        "print(f\"True values: y = {y_train}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exE2h_ka6P7d"
      },
      "source": [
        "###  Преимущества и недостатки метода"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVQBHdhL6P7d"
      },
      "source": [
        "В настоящее время метод обратного распространения ошибки фактически стал стандартом при обучении широкого спектра современных архитектур нейронных сетей. Этот метод даёт итерационное решение задачи поиска минимума функционала ошибки, последовательно подстраивая веса нейронной сети в ходе обучения. К сожалению, такой подход не гарантирует, что в ходе обучения нейронной сети мы действительно достигнем абсолютного (глобального) минимума функции потерь. Кроме того, в силу итерационной природы алгоритма, для обучения может потребоваться огромное количество циклов, что иногда приводит к необходимости проводить вычисления непрерывно в течение дней, недель или даже месяцев. Остановимся ещё на некоторых трудностях, которые могут сопровождать метод обратного распространения ошибки:  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_1OXrIP6P7d"
      },
      "source": [
        "* Остановка обучения в локальном минимуме функции потерь\n",
        "\n",
        "    На функцию потерь нейронной сети можно смотреть как на определенную поверхность в пространстве высокой размерности (размерность пространства соответствует числу весов нейронной сети). Скажем, если бы у нейронной сети было всего два веса, то такая поверхность была бы похожа на земной рельеф.\n",
        "\n",
        "    Поверхность функции потерь во всех возникающих на практике случаях достаточно сложна и содержит высокоразмерные аналоги холмов, впадин, долин и всевозможных их комбинаций. Применяя градиентный спуск, мы фактически движемся по такой поверхности в направлении самого \"крутого\" склона вниз, начиная своё движение из какой-то фиксированной точки поверхности. Может так оказаться, что мы начали своё движение по поверхности неподалёку от небольшой впадины (локального минимума функции потерь) и, \"закатившись\" в него, не сможем больше из него выбраться, даже если совсем неподалёку в пространстве весов сети будет присутствовать значительно более \"глубокий\" минимум — все пути из неглубокого локального минимума находятся в направлении, противоположном тому, согласно которому мы движемся при методе градиентного спуска. Чтобы \"выпрыгнуть\" из такого нежелательного локального минимума, может потребоваться кратковременно увеличить скорость обучения (фактически размер шага). Проблема выбора алгоритма задания оптимального шага обучения во время градиентного спуска в общем случае не решена.\n",
        "\n",
        "    Наглядные визуализации поверхностей функций потерь настоящих нейронных сетей можно найти на странице [проекта LossLandscape](https://losslandscape.com/). Интерактивный инструмент по визуализации градиентного спуска доступен по ссылке: [LossLandscape Explorer](https://losslandscape.com/explorer)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og9aLY0t6P7d"
      },
      "source": [
        "* Паралич сети\n",
        "\n",
        "    Пусть мы обучаем многослойную нейронную сеть, в которой в качестве функции активации нейронов используются сигмоидальные функции (логистическая функция или гиперболический тангенс). Если мы допустим слишком сильное обновление весов у большого числа нейронов, чего можно легко добиться выбором слишком большой величины скорости (шага) обучения, то дальнейшее обучение сети фактически может остановиться. Дело в том, что в области больших по модулю значений аргумента сигмоидальной функции она практически не изменяется, а значит её производная слабо отличается от нуля. Так как обновление весов на следующем шаге градиентного спуска будет пропорционально значению производной функции активации, то оно также будет близко к нулю. Такой переход нейронов в \"насыщение\" может быть уже необратимым, и методу градиентного спуска потребуется неограниченно много времени для возвращения сети в исходное \"рабочее\" состояние."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx8IWg246P7e"
      },
      "source": [
        "##  Функции потерь (loss functions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrQExk1W6P7e"
      },
      "source": [
        "Предположим, у нас есть нейронная сеть с некоторыми весами. Прежде всего мы должны понять, насколько она точна, то есть насколько наши ожидания соответствуют результату работы нейронной сети. Мы подали на вход нейронной сети изображение, сигналы прошли через наши слои и функции активации вперёд **(forward propagation)**, и на выходе мы имеем некоторый ответ. Как его оценить? Насколько он точен?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXr1A-7v6P7e"
      },
      "source": [
        "Для оценки соответствия полученного результата ожидаемому, используют функцию потерь (loss function). Значение функции потерь даёт количественную оценку величины такого соответствия."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPiwD7tO6P7e"
      },
      "source": [
        "Функция потерь в нейронной сети принимает два аргумента:\n",
        "* вектор значений, который мы считаем априорно верным;\n",
        "* вектор значений конечных выходов модели, который должен соответствовать априорно верному.\n",
        "\n",
        "Важно заметить, что для успешного обучения модели методом градиентного спуска мы должны потребовать от функции потерь дифференцируемости и ограниченности снизу.\n",
        "\n",
        "[Документация по функциям потерь в PyTorch](https://pytorch.org/docs/stable/nn.html#loss-functions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWO5B_cw6P7e"
      },
      "source": [
        "###  Mean Squared Error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFejzSEr6P7e"
      },
      "source": [
        "Mean Squared Error (MSE) — это средняя квадратическая ошибка. Данная функция потерь очень популярная, поскольку она проста для понимания и реализации, и в целом работает довольно хорошо. Применяется преимущественно **при решении задач регрессии**, когда модель предсказывает вещественное число. Чтобы рассчитать MSE, нужно взять разницу между предсказаниями вашей модели и эталонными значениями, возвести в квадрат и затем усреднить по всему набору данных (в случае обучения по мини-батчам — по размеру батча).\n",
        "Результат всегда положительный, независимо от знака предсказанных и истинных значений, и идеальное значение равно 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-3uJMGq6P7e"
      },
      "source": [
        "Для $i$-го объекта выборки, если выходной вектор состоит из $C$ компонент, средняя квадратическая ошибка между выходом модели $\\hat{y}$ и целевым вектором $y$ будет равна\n",
        "\n",
        "$$MSE_i(\\hat{y},y)=\\frac{1}{C} \\sum_{k=1}^{C}{(\\hat{y}_{ik}-y_{ik})^2}$$\n",
        "\n",
        "При вычислении по всему набору данных (или по мини-батчу) из $N$ объектов ошибка на отдельных объектах усредняется:\n",
        "\n",
        "$$MSE=\\frac{1}{N}\\sum_{i=1}^{N}MSE_i$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl90LnbA6P7f"
      },
      "source": [
        "[MSE Loss в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss):\n",
        "```python\n",
        "torch.nn.MSELoss()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoIC6m7g6P7f",
        "outputId": "68bd3da9-3d24-4327-8a37-01d140ae42e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_output: tensor([ 0.5000, -0.2500,  0.7500])\n",
            "target: tensor([1.0000, 0.2500, 0.2500])\n",
            "loss_mse: 0.25\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.MSELoss()\n",
        "\n",
        "# batch of 1 element and 3 components in output vector\n",
        "model_output = torch.Tensor([0.5, -0.25, 0.75])\n",
        "print(f\"model_output: {model_output}\")\n",
        "\n",
        "target = torch.Tensor([1, 0.25, 0.25])\n",
        "print(f\"target: {target}\")\n",
        "\n",
        "loss_mse = criterion(model_output, target)\n",
        "print(f\"loss_mse: {loss_mse}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0e_U1zY6P7f"
      },
      "source": [
        "* **Преимущество:** Использование MSE в качестве функции потерь даёт основания ожидать, что обученная с ней модель не имеет сильных \"выбросов\" в величине ошибки. Любой большой выброс в невязке $|\\hat {Y_i} - Y_i| \\ggg 0 $ при вычислении MSE был бы возведён в квадрат и дал бы вовсе огромный вклад в итоговое значение функции потерь.\n",
        "\n",
        "\n",
        "* **Недостаток:** Как логично следует из описанного выше преимущества  MSE, данная функция потерь в первую очередь сильно штрафует модель за наличие выбросов в предсказаниях.  Для ряда практически важных задач, тем не менее, важнее оказывается наиболее высокая точность работы на абсолютном большинстве входных примеров, нежели отсутствие одиночных выбросов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFbq05Q36P7f"
      },
      "source": [
        "###  Mean Absolute Error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz0qZ_MU6P7f"
      },
      "source": [
        "Средняя абсолютная ошибка (MAE) — это величина, которая измеряет среднюю по всем образцам величину невязки $|\\hat{Y_i} - Y_i|$. Также может применяться **при решении задач регрессии**. Несмотря на то, что определение этой функции потерь похоже на MSE (MSE Loss можно назвать $L_2$ ошибкой, а MAE в этом смысле можно назвать $L_1$ ошибкой), средняя абсолютная ошибка имеет существенно другие свойства."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTd3xbuA6P7f"
      },
      "source": [
        "Для $i$-го объекта выборки, если выходной вектор состоит из $C$ компонент, средняя абсолютная ошибка между выходом модели $\\hat{y}$ и целевым вектором $y$ будет равна\n",
        "\n",
        "$$MAE_i(\\hat{y},y)=\\frac{1}{C} \\sum_{k=1}^{C}{\\left| \\hat{y}_{ik}-y_{ik}\\right|}$$\n",
        "\n",
        "При вычислении по всему набору данных (или по мини-батчу) из $N$ объектов ошибка на отдельных объектах усредняется:\n",
        "\n",
        "$$MAE=\\frac{1}{N}\\sum_{i=1}^{N}MAE_i$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWef1Ky96P7g"
      },
      "source": [
        "[MAE Loss в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html#torch.nn.L1Loss):\n",
        "```python\n",
        "torch.nn.L1Loss()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo-XI4Sc6P7g",
        "outputId": "91750a0b-9ade-43b6-cf94-3dc970b21024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_output: tensor([ 0.5000, -0.2500,  0.7500])\n",
            "target: tensor([1.0000, 0.2500, 0.2500])\n",
            "loss_mae: 0.5\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.L1Loss()\n",
        "\n",
        "# batch of 1 element and 3 components in output vector\n",
        "model_output = torch.Tensor([0.5, -0.25, 0.75])\n",
        "print(f\"model_output: {model_output}\")\n",
        "\n",
        "target = torch.Tensor([1, 0.25, 0.25])\n",
        "print(f\"target: {target}\")\n",
        "\n",
        "loss_mae = criterion(model_output, target)\n",
        "print(f\"loss_mae: {loss_mae}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULud93T86P7g"
      },
      "source": [
        "* **Преимущество:** Поскольку при вычислении MAE вычисляется абсолютное значение ошибки, данная метрика не придаёт такого большого значения \"выбросам\", как MSE — все ошибки учитываются равнозначно в единой линейной шкале.\n",
        "\n",
        "\n",
        "* **Недостаток:**  Недостаток применения MAE в качестве функции потерь при обучении модели напрямую вытекает из преимуществ. Обученная с MAE модель может показывать хорошие (или даже отличные) результаты в большинстве случаев, но на отдельных примерах может допускать большую ошибку. Если специфика решаемой задачи не позволяет нам пренебречь такими одиночными большими выбросами, то следует воздержаться от применения данной функции потерь."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTJzU9T86P7g"
      },
      "source": [
        "###  Cross-Entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKlGCn436P7g"
      },
      "source": [
        "Кросс-энтропия — классическая функция потерь **при решении задач классификации**. Возникновение такой формы измерения различия между целевой переменной и предсказанием модели в задаче классификации мы уже рассматривали на лекции про линейные классификаторы. Напомним здесь формулу, по которой она рассчитывается."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f79nf7zg6P7g"
      },
      "source": [
        "Для $i$-го объекта выборки, если выходной вектор состоит из $C$ компонент (**логитов** для $C$ классов), кросс-энтропия между выходом модели $\\hat{y}$ и целевым вектором $y$ будет равна\n",
        "\n",
        "$$CE_i(\\hat{y},y)= - \\sum_{k=1}^{C}{y_{ik}\\cdot\\text{log}\\left(\\frac{\\exp(\\hat{y}_{ik})}{\\sum_{j=1}^{C}\\exp(\\hat{y}_{ij})}\\right)}$$\n",
        "\n",
        "При вычислении по всему набору данных (или по мини-батчу) из $N$ объектов ошибка на отдельных объектах усредняется:\n",
        "\n",
        "$$CE=\\frac{1}{N}\\sum_{i=1}^{N}CE_i$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEbIBJN36P7h"
      },
      "source": [
        "[Cross-Entropy Loss в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss):\n",
        "```python\n",
        "torch.nn.CrossEntropyLoss()\n",
        "```\n",
        "\n",
        "Обратите внимание, что Cross-Entropy Loss в PyTorch уже включает в себя Softmax и принимает в качестве выхода модели логиты. Поэтому при использовании данной фукции потерь ставить на последнем слое нейронной сети Softmax **не нужно**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhllBXsr6P7h",
        "outputId": "a715cfdb-a371-416a-e381-8e664e45284c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_output:\n",
            " tensor([[0.8509, 0.9979, 0.1652],\n",
            "        [0.7225, 0.2251, 0.3650],\n",
            "        [0.3164, 0.6769, 0.3530]])\n",
            "target: tensor([1, 0, 2])\n",
            "loss_ce: 0.9587342143058777\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_output = torch.rand(3, 3)\n",
        "print(f\"model_output:\\n {model_output}\")\n",
        "\n",
        "target = torch.empty(3, dtype=torch.long).random_(3)\n",
        "print(f\"target: {target}\")\n",
        "\n",
        "loss_ce = criterion(model_output, target)\n",
        "print(f\"loss_ce: {loss_ce}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X-ebOQn6P7h"
      },
      "source": [
        "$$CE_1 = - \\text{log}\\left(\\frac{\\exp{(0.7950)}}{\\exp{(0.7950)}+\\exp{(0.3205)}+\\exp{(0.4384)}}\\right)$$\n",
        "\n",
        "$$CE_2 = - \\text{log}\\left(\\frac{\\exp{(0.1743)}}{\\exp{(0.8802)}+\\exp{(0.5885)}+\\exp{(0.1743)}}\\right)$$\n",
        "\n",
        "$$CE_3 = - \\text{log}\\left(\\frac{\\exp{(0.5399)}}{\\exp{(0.3752)}+\\exp{(0.5399)}+\\exp{(0.0035)}}\\right)$$\n",
        "\n",
        "$$CE = \\frac{1}{3}(CE_1 + CE_2 + CE_3)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ1we5iW6P7h",
        "outputId": "459e87eb-a987-4c41-dfed-9d6ab32ea16c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hand-calculated loss_ce: 1.0814430511898192\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "ce_1 = -np.log(np.exp(0.7950) / (np.exp(0.7950) + np.exp(0.3205) + np.exp(0.4384)))\n",
        "ce_2 = -np.log(np.exp(0.1743) / (np.exp(0.8802) + np.exp(0.5885) + np.exp(0.1743)))\n",
        "ce_3 = -np.log(np.exp(0.5399) / (np.exp(0.3752) + np.exp(0.5399) + np.exp(0.0035)))\n",
        "\n",
        "ce = (1 / 3) * (ce_1 + ce_2 + ce_3)\n",
        "print(f\"hand-calculated loss_ce: {ce}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGJdeX2y6P7h"
      },
      "source": [
        "* **Преимущества:** Важное свойство кросс-энтропии — возможность работать с весами для классов, а значит и возможность применения этой функции потерь при работе с несбалансированным датасетом."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFPUsW3l6P7h"
      },
      "source": [
        "### Negative Log Likelihood\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IESxlIVh6P7i"
      },
      "source": [
        "Еще одной функцией потерь, которая может использоваться при решении задач классификации наряду с Cross-Entropy Loss и может встречаться при работе в PyTorch, является обратный логарифм правдоподобия (Negative Log Likelihood Loss, NLLLoss).\n",
        "\n",
        "Данная функция потерь отличается от Cross-Entropy Loss тем, что в качестве выхода модели она ожидает **не логиты**, а **логарифмы вероятностей для классов**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubRrFgkm6P7i"
      },
      "source": [
        "Для $i$-го объекта выборки, если выходной вектор состоит из $C$ компонент (**логарифмов вероятностей** для $C$ классов), обратный логарифм правдоподобия между выходом модели $\\hat{y}$ и целевым вектором $y$ будет равен\n",
        "\n",
        "$$NLL_i(\\hat{y},y)= - \\sum_{k=1}^{C}{y_{ik}\\cdot\\hat{y}_{ik}}$$\n",
        "\n",
        "При вычислении по всему набору данных (или по мини-батчу) из $N$ объектов ошибка на отдельных объектах усредняется:\n",
        "\n",
        "$$NLL=\\frac{1}{N}\\sum_{i=1}^{N}NLL_i$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwGiPRGB6P7i"
      },
      "source": [
        "Для того, чтобы пользоваться NLLLoss при решении задачи классификации, к логитам, которые выдает модель, необходимо дополнительно применять Softmax и брать от результата натуральный логарифм, и уже результат такого вычисления передавать в NLLLoss. В PyTorch вычисление логарифма от результата применения Softmax к логитам реализовано в модуле [`LogSoftmax`](https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html). Взаимоотношение между NLLLoss и CrossEntropyLoss можно выразить следующей иллюстрацией:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5Fqgz-c6P7i"
      },
      "source": [
        "<img src=\"https://edunet.kea.su/repo/EduNet-content/L05/out/ce_loss_vs_nll_loss.png\" width='900'>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdOvt50I6P7i",
        "outputId": "2588cb1b-6a0e-4658-ed1b-d56ed4a6b9c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_output:\n",
            " tensor([[0.8509, 0.9979, 0.1652],\n",
            "        [0.7225, 0.2251, 0.3650],\n",
            "        [0.3164, 0.6769, 0.3530]])\n",
            "logprobs:\n",
            " tensor([[-0.9791, -0.8321, -1.6648],\n",
            "        [-0.8362, -1.3335, -1.1937],\n",
            "        [-1.2446, -0.8840, -1.2079]])\n",
            "target: tensor([1, 0, 2])\n",
            "loss_nll: 0.9587342143058777\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.NLLLoss()\n",
        "logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "print(f\"model_output:\\n {model_output}\")\n",
        "\n",
        "logprobs = logsoftmax(model_output)\n",
        "print(f\"logprobs:\\n {logprobs}\")\n",
        "\n",
        "print(f\"target: {target}\")\n",
        "\n",
        "loss_nll = criterion(logprobs, target)\n",
        "print(f\"loss_nll: {loss_nll}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cauH0OA_6P7i"
      },
      "source": [
        "Двойственность NLLLoss и CrossEntropyLoss может немного путать. Она возникла из-за того, что NLLLoss была исторически раньше реализована в библиотеке. Было принято на выходе модели ставить LogSoftmax, и использовать NLLLoss. Позднее была реализована функция CrossEntropyLoss, которая включала в себя одновременно LogSoftmax и NLLLoss и позволяла не добавлять в модель лишний модуль. За счет такого упрощения использование CrossEntropyLoss быстро стало более популярно. Реализацию NLLLoss, по всей видимости, оставили в библиотеке скорее для обратной совместимости."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKcZ4pKM6P7j"
      },
      "source": [
        "Еще одним важным вытекающим отличием в использовании NLLLoss и CrossEntropyLoss является следующее. После обучения модели мы хотим пользоваться ей по назначению — для классификации. Иногда нам хочется, чтобы мы могли смотреть на выходы модели как на вероятности отнесения объектов к различным классам.\n",
        "\n",
        "* При использовании связки LogSoftmax + NLLLoss на выходе модели имеем логарифмы от вероятностей, и для получения самих вероятностей мы должны взять экспоненту от выхода модели.\n",
        "\n",
        "* При использовании CrossEntropyLoss на выходе модели имеем логиты, и для получения вероятностей мы должны применить Softmax-преобразование."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtKMbEW76P7j"
      },
      "source": [
        "[Объяснение Negative Log Likelihood Loss](https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/)\n",
        "\n",
        "[Блог-пост о соотношении Cross-Entropy Loss и Negative Log Likelihood Loss](https://jamesmccaffrey.wordpress.com/2020/06/11/pytorch-crossentropyloss-vs-nllloss-cross-entropy-loss-vs-negative-log-likelihood-loss/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noiCsh2D6P7j"
      },
      "source": [
        "###  Binary Cross-Entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB6Uvkf96P7j"
      },
      "source": [
        "В частном случае, когда количество классов равно двум (**задача бинарной классификации**), их можно закодировать одним числом: $0$ — для первого класса, и $1$ — для второго, то сумму $\\sum_{k=1}^{C}$ в формуле Cross-Entropy Loss можно расписать в явном виде."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY93F8q56P7k"
      },
      "source": [
        "Для $i$-го объекта выборки, когда выход модели является скаляром (**вероятностью** отнесения объекта к классу $1$), бинарная кросс-энтропия между выходом модели $\\hat{y}$  и целевым значением $y$ будет равна\n",
        "\n",
        "$$BCE_i(\\hat{y},y)= - [{y_i\\cdot\\text{log}(\\hat{y}_{i})+(1-y_i)\\cdot\\text{log}(1-\\hat{y}_{i})}]$$\n",
        "\n",
        "При вычислении по всему набору данных (или по мини-батчу) из $N$ объектов ошибка на отдельных объектах усредняется:\n",
        "\n",
        "$$BCE=\\frac{1}{N}\\sum_{i=1}^{N}BCE_i$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F4XzlZm6P7k"
      },
      "source": [
        "[Binary Cross-Entropy Loss в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss):\n",
        "\n",
        "```python\n",
        "torch.nn.BCELoss()\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWVL3oTC6P7k"
      },
      "source": [
        "Важной особенностью BCELoss является то, что она ждёт одно число выхода сети и одно число как верный результат. Тут используется не one-hot кодировка для двух классов, а **одно число: 0 — первый класс, 1 — второй класс.** При этом значения целевой переменной должны быть представлены как вещественные (float) числа."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE1L5FUf6P7l",
        "outputId": "339ad50d-0490-4f1f-fd3e-a201bab9e5d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_output: tensor([0.9506])\n",
            "target: tensor([0.])\n",
            "loss_bce: 3.008212089538574\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.BCELoss()\n",
        "\n",
        "model_output = torch.rand(1)\n",
        "print(f\"model_output: {model_output}\")\n",
        "\n",
        "target = torch.empty(1).random_(2)\n",
        "print(f\"target: {target}\")\n",
        "\n",
        "loss_bce = criterion(model_output, target)\n",
        "print(f\"loss_bce: {loss_bce}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqFcTPMM6P7l"
      },
      "source": [
        "Если классы \"абсолютно полностью\" не совпали, то возникает ситуация взятия логарифма от 0, а он не определён и стремится к бесконечности, поэтому берётся \"обрезанная бесконечность\" равная 100.\n",
        "\n",
        "Далее, если сэмплов несколько, то по умолчанию берётся среднее по семплам. См. аргумент `reduction`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIQm7wRi6P7m",
        "outputId": "a8363f78-97da-4f56-935d-3e2a8141355a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_output: tensor([1., 1., 1., 1., 1.])\n",
            "target: tensor([0., 0., 0., 0., 0.])\n",
            "loss_bce: 100.0\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.BCELoss()\n",
        "\n",
        "model_output = torch.ones((5))\n",
        "print(f\"model_output: {model_output}\")\n",
        "\n",
        "target = torch.zeros(5)\n",
        "print(f\"target: {target}\")\n",
        "\n",
        "loss_bce = criterion(model_output, target)\n",
        "print(f\"loss_bce: {loss_bce}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNwTTqy46P7m"
      },
      "source": [
        "### Binary Cross-Entropy With Logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMC2DMUj6P7m"
      },
      "source": [
        "Для того, чтобы выход модели при бинарной классификации представлял собой **вероятность отнесения объекта к классу $1$**, на выходе модели мы должны использовать логистическую функцию (sigmoid), которая переведет взвешенную сумму входов (логит) в значение от $0$ до $1$, которое и можно будет интерпретировать как вероятность и передать в BCELoss.\n",
        "\n",
        "По аналогии с NLLLoss и CrossEntropyLoss, у BCELoss есть своя \"пара\": BCEWithLogitsLoss. Эта функция потерь совмещает в себе две операции:\n",
        "\n",
        "* применение логистической функции Sigmoid\n",
        "* расчет BCELoss\n",
        "\n",
        "Как можно понять из названия, BCEWithLogitsLoss на вход ожидает логиты. Взаимоотношение между BCELoss и BCEWithLogitsLoss можно отобразить такой иллюстрацией:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i0HnhFl6P7n"
      },
      "source": [
        "<img src=\"https://edunet.kea.su/repo/EduNet-content/L05/out/bce_loss_vs_bce_with_logits_loss.png\" width='900'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC9eIapC6P7n"
      },
      "source": [
        "### Итоги"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hv-1vNN6P7n"
      },
      "source": [
        "Кросс-энтропия предпочтительнее для задач *классификации*, так как от модели требуется предсказание *вероятности класса* при известной априорной вероятности. Средняя квадратическая и средняя абсолютная ошибки предпочтительны для задач *регрессии*, когда от модели требуется предсказание произвольных вещественных чисел.\n",
        "\n",
        "И то, и другое можно рассматривать как оценки максимального правдоподобия, просто с различными предположениями о зависимой переменной.\n",
        "\n",
        "Здесь были рассмотрены лишь наиболее общие и часто применяющиеся функции потерь для основополагающих задач машинного обучения: классификации и регрессии. Однако на практике могут возникать случаи, когда от исследователя или разработчика нейронной сети требуется сконструировать свою собственную функцию потерь под свою собственную задачу. В PyTorch, помимо рассмотренных, есть реализация и других функций потерь для других задач. Также свою \"кастомную\" функцию потерь можно написать самостоятельно.\n",
        "\n",
        "[Обзор функций потерь в PyTorch с примером написания своей собственной функции (custom loss function)](https://neptune.ai/blog/pytorch-loss-functions)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1pxCS1q6P7n"
      },
      "source": [
        "##  Функции активации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4DXhSAx6P7n"
      },
      "source": [
        "Минимальным функциональным элементом нейронной сети является одиночный нейрон. В нейроне осуществляются две операции:\n",
        "1. Вычисляется взвешенная и смещенная сумма его входов\n",
        "$$ s=\\sum_{i=1}^n w_i \\cdot x_i+b=WX+b,$$\n",
        "где $W$ — вектор весов, $X$ — вектор входных значений, $b$ — величина смещения.\n",
        "\n",
        "2. К получившейся величине применяется некоторая нелинейная функция, называемая функцией активации\n",
        "$$ y = f(s)$$\n",
        "\n",
        "\n",
        "Взвешенная и смещенная сумма входов $s$ может принимать произвольное значение на вещественной прямой: $s \\in \\mathbb{R}$. Данное значение  передается в функцию активации, которая, как правило, обладает другим множеством возможных значений."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiWshJZX6P7o"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/neurons_output.png\" width=\"900\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YldF1da6P7o"
      },
      "source": [
        "Идея применения функций активации в структуре искусственных нейронных сетей обусловлена биологической аналогией. Известно, что в биологических нейронных сетях имеется аналог нелинейной функции активации: существует пороговый потенциал, только после достижения которого происходит возбуждение (активация) нейрона и, как следствие, распространение сигнала далее по нейронной сети.\n",
        "\n",
        "Именно таким простейшим образом ведёт себя пороговая функция активации, которая использовалась при построении первых искусственных нейронных сетей — перцептронов:\n",
        "\n",
        "$f(x) =\n",
        "\\begin{cases}\n",
        "0, &\\text{$x<b$} \\\\\n",
        "1, &\\text{$x\\geq b$}\n",
        "\\end{cases}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvKGNzWK6P7o"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/threshold_function_plot.png\" width=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK-11oAe6P7p"
      },
      "source": [
        "Построенная с пороговой функцией активации нейронная сеть обладает ключевым недостатком, не позволяющим фактически использовать данную функцию активации на практике. В силу того, что производная функции активации тривиальна почти всюду на числовой прямой:\n",
        "\n",
        "$f'(x) =\n",
        "\\begin{cases}\n",
        "0, &\\text{$x\\neq b$} \\\\\n",
        "?, &\\text{$x= b$}\n",
        "\\end{cases}\n",
        "$\n",
        "\n",
        "не представляется возможным использовать метод градиентного спуска для оптимизации параметров нейронной сети."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fEa9HJB6P7p"
      },
      "source": [
        "###  Свойства функций активации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSzlISkf6P7p"
      },
      "source": [
        "Функции активации должны обладать следующими свойствами:\n",
        "\n",
        "* **Нелинейность:** функция активации необходима для введения нелинейности в нейронные сети. Если функция активации не применяется, выходной сигнал становится простой линейной функцией. Нейронная сеть без нелинейностей будет действовать как линейная модель с ограниченной способностью к обучению:\n",
        "$$\\hat{y}=NN(X,W_1,...,W_n)=X\\cdot W_1\\cdot ...\\cdot W_n=X\\cdot W$$\n",
        "Только нелинейные функции активации позволяют нейронным сетям решать задачи аппроксимации нелинейных функций:\n",
        "$$\\hat{y}=NN(X,W_1,...,W_n)=\\sigma(...\\sigma(X\\cdot W_1)...\\cdot W_n)\\neq X\\cdot W$$\n",
        "\n",
        "* **Дифференцируемость:** функции активации должны быть способными пропускать градиент, чтобы было возможно оптимизировать параметры сети градиентными методами, в частности использовать алгоритм обратного распространения ошибки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrzfyu5t6P7q"
      },
      "source": [
        "###  Различные функции активации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyKT2eDN6P7q"
      },
      "source": [
        "Рассмотрим наиболее популярные функции активации и обсудим их преимущества и недостатки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3OKRJ4R6P7q"
      },
      "source": [
        "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/L05/popular_activation_functions.png\" width=\"700\"></center>\n",
        "\n",
        "<center><em>Source: <a href=\"https://arxiv.org/pdf/1911.05187.pdf\">AI in Pursuit of Happiness, Finding Only Sadness: Multi-Modal Facial Emotion Recognition Challenge</a></em></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RviutDcF6P7r"
      },
      "source": [
        "####  **Логистическая функция**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dJp9evK6P7r"
      },
      "source": [
        "Логистическая (сигмоидальная) функция — используется в задачах бинарной классификации, в основном после выхода последнего нейрона. Позволяет определить вероятность принадлежности к одному из двух классов (0 или 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2xBCM7I6P7r"
      },
      "source": [
        "$$\\sigma(x)=\\frac{1}{1+e^{-x}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB0RoutR6P7s"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/activation_function_sigmoid.png\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnJSHUkF6P7s"
      },
      "source": [
        "Примечательным свойством логистической функции является то, что ее производная выражается через саму функцию. Это значит, что зная значение функции в точке, вычислить значение производной в этой точке очень легко:\n",
        "\n",
        "$$ \\frac{d}{dx}\\sigma(x) = \\frac{d}{dx}(1+e^{-x})^{-1} = \\frac{e^{-x}}{(1+e^{-x})^{2}} = \\frac{1}{1+e^{-x}} \\cdot \\frac{1+e^{-x}-1}{1+e^{-x}} = \\sigma(x)\\cdot(1-\\sigma(x))$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79Qyc-j-6P7s"
      },
      "source": [
        "В отличие от пороговой функции активации, где у нейрона было всего два состояния: \"активирован\" или \"не активирован\", с логистической функцией для нейрона возможны значения \"активирован на 50%\", \"активирован на 20%\" и так далее. Если активированы несколько нейронов, можно найти нейрон с наибольшим значением активации.\n",
        "\n",
        "Так как существуют промежуточные значения на выходе нейрона, **процесс обучения проходит более гладко и быстро**, а вероятность появления нескольких полностью активированных нейронов во время тренировки снижается по сравнению с пороговой функцией активации (хотя это зависит от того, что вы обучаете и на каких данных)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O4epYsv6P7t"
      },
      "source": [
        "[Сигмоидальная функция активации в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html):\n",
        "```python\n",
        "torch.nn.Sigmoid()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqaxzP5N6P7t",
        "outputId": "98720396-b09a-42e0-e64b-80521eeb4d8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_values: tensor([  3.2233,   7.9277,  -0.3715,  -7.1913, -12.9547])\n",
            "activation_sig: tensor([9.6170e-01, 9.9964e-01, 4.0817e-01, 7.5251e-04, 2.3650e-06])\n"
          ]
        }
      ],
      "source": [
        "activation = nn.Sigmoid()\n",
        "input_values = torch.randn(5) * 5\n",
        "activation_sig = activation(input_values)\n",
        "print(f\"input_values: {input_values}\\nactivation_sig: {activation_sig}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jaz34BVL6P7t"
      },
      "source": [
        "Сигмоида выглядит гладкой и подобна пороговой функции.\n",
        "\n",
        "**Достоинства:**\n",
        "\n",
        "Во-первых, сигмоида нелинейна по своей природе, а комбинация таких функций производит тоже нелинейную функцию. Поэтому мы можем конструировать многослойные сети.\n",
        "\n",
        "Еще одно достоинство такой функции — она гладкая, следовательно, улучшается гладкость градиента, в отличие от ступенчатой функции."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HcAElqR6P7u"
      },
      "source": [
        "**Недостатки:**\n",
        "\n",
        "Насыщение сигмоиды приводит к затуханию градиентов. Крайне нежелательное свойство сигмоиды заключается в том, что при насыщении функции с той или иной стороны (0 или 1) градиент на этих участках становится близок к нулю. Напомним, что в процессе обратного распространения ошибки данный (локальный) градиент умножается на общий градиент. Следовательно, если локальный градиент очень мал, он фактически обнуляет общий градиент. В результате сигнал почти не будет проходить через нейрон к его весам. Кроме того, следует быть очень осторожным при инициализации весов сигмоидных нейронов, чтобы предотвратить насыщение. Например, если исходные веса имеют слишком большие значения, большинство нейронов перейдет в состояние насыщения, в результате чего сеть будет плохо обучаться."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym8hRTjt6P7u"
      },
      "source": [
        "Выход сигмоиды не центрирован относительно нуля. Это свойство является нежелательным, поскольку нейроны в последующих слоях будут получать значения, которые не центрированы относительно нуля, что оказывает влияние на динамику градиентного спуска. Если значения, поступающие в нейрон, всегда положительны (например, $x > 0$ поэлементно в $f = wx + b$), то в процессе обратного распространения ошибки все градиенты весов $w$ будут либо положительны, либо отрицательны (в зависимости от градиента всего выражения $f$). Это может привести к нежелательной зигзагообразной динамике обновлений весов. Однако следует отметить, что, когда эти градиенты суммируются по батчу, итоговое обновление весов может иметь различные знаки, что отчасти нивелирует описанный недостаток. Таким образом, отсутствие центрирования является неудобством, но имеет менее серьезные последствия по сравнению с проблемой насыщения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB1xNFwd6P7u"
      },
      "source": [
        "####  **Гиперболический тангенс**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcOAwLy46P7v"
      },
      "source": [
        "Гиперболический тангенс схож с логистической функцией. Он определяется следующей формулой:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgXwOKTs6P7v"
      },
      "source": [
        "$$tanh(x)=\\frac{e^x - e^{-x}}{e^x+e^{-x}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5EL3GVh6P7v"
      },
      "source": [
        "Также гиперболический тангенс может быть выражен через логистическую функцию:\n",
        "\n",
        "$$tanh(x) = 2\\cdot\\sigma(2x)-1$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy7qHZz36P7v"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/activation_function_tanh.png\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6XKm-KW6P7v"
      },
      "source": [
        "Производная гиперболического тангенса также [выражается через саму функцию](https://socratic.org/questions/what-is-the-derivative-of-tanh-x):\n",
        "\n",
        "$$ \\frac{d}{dx}tanh(x)=1-tanh^2(x)$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZo85tPK6P7v"
      },
      "source": [
        "Гиперболический тангенс симметричен относительно нуля и может принимать как положительные, так и отрицательные значения. Данное свойство гиперболического тангенса оказывается важным, в частности, при построении рекуррентных нейронных сетей. При использовании в рекуррентных сетях, получаемые на выходе $\\tanh (x)$ положительные или отрицательные значения могут не только увеличивать величину скрытого состояния в ячейках памяти, но и уменьшать их. Подробнее с устройством рекуррентных нейронных сетей мы познакомимся в последующих лекциях нашего курса."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVpQe0N26P7v"
      },
      "source": [
        "**Достоинства**: В силу схожего определения, гиперболический тангенс обладает основными достоинствами описанной выше логистической функции. Кроме того, множество значений данной функции активации симметрично относительно нуля $[-1,1]$. Использование гиперболического тангенса в качестве функции активации хорошо подходит для последовательного соединения полносвязных слоёв нейронной сети.\n",
        "\n",
        "**Недостатки**: Производная гиперболического тангенса по виду аналогична производной логистической функции, следовательно, при использовании гиперболического тангенса в качестве функции активации мы также можем столкнуться с проблемой затухания градиентов в области насыщения функции.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnY2GADo6P7w"
      },
      "source": [
        "[Гиперболический тангенс в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html):\n",
        "```python\n",
        "torch.nn.Tanh()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l_feD8m6P7w",
        "outputId": "4a7128a6-799a-4fe8-b9bc-adc436900729"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_values: tensor([11.1529,  4.3029,  0.5081, -3.8456, -1.9058])\n",
            "activation_tanh: tensor([ 1.0000,  0.9996,  0.4685, -0.9991, -0.9567])\n"
          ]
        }
      ],
      "source": [
        "activation = nn.Tanh()\n",
        "input_values = torch.tensor([11.1529, 4.3029, 0.5081, -3.8456, -1.9058])\n",
        "activation_tanh = activation(input_values)\n",
        "print(f\"input_values: {input_values}\\nactivation_tanh: {activation_tanh}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zXhP4Rk6P7w"
      },
      "source": [
        "####  **ReLU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGcKZoD56P7w"
      },
      "source": [
        "Часто на практике применяется функция активации ReLU. Значение данной функции равно нулю для всех отрицательных входных значений и равно входному значению, если оно неотрицательно. Название ReLU (Rectified Linear Unit), \"выпрямитель\", связана с электротехнической аналогией — график вольт-амперной характеристики идеального выпрямительного диода похож на график функции ReLU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfU4iSYa6P7w"
      },
      "source": [
        "$$ReLU(x)=max(0,x)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCF0WUPl6P7w"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/activation_function_relu.png\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Npxh5id6P7x"
      },
      "source": [
        "Производная ReLU:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFTKT_AU6P7x"
      },
      "source": [
        "$$\\frac{d}{dx}ReLU(x) =\n",
        "\\begin{cases}\n",
        "\\frac{d}{dx}0, &\\text{$x<0$} \\\\\n",
        "\\frac{d}{dx}x, &\\text{$x\\geq0$}\n",
        "\\end{cases}=\n",
        "\\begin{cases}\n",
        "0, &\\text{$x<0$} \\\\\n",
        "1, &\\text{$x\\geq0$}\n",
        "\\end{cases}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZHDnd5W6P7x"
      },
      "source": [
        "[ReLU в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html):\n",
        "```python\n",
        "torch.nn.ReLU()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEtEocMb6P7x",
        "outputId": "5d685bdc-22cd-44ef-fc83-30167c8c7f95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_values: tensor([-2.0400,  0.2595,  0.5425, -0.7905,  0.1925])\n",
            "activation_relu: tensor([0.0000, 0.2595, 0.5425, 0.0000, 0.1925])\n"
          ]
        }
      ],
      "source": [
        "activation = nn.ReLU()\n",
        "input_values = torch.randn(5)\n",
        "activation_relu = activation(input_values)\n",
        "print(f\"input_values: {input_values}\\nactivation_relu: {activation_relu}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5i_pQwQ6P7x"
      },
      "source": [
        "Рассмотрим положительные и отрицательные стороны ReLU.\n",
        "\n",
        "**Достоинства:**\n",
        "\n",
        "Функция ReLU не требует проведения вычислений в вещественной арифметике, как того требуют логистическая функция или гиперболический тангенс. Кроме того, производная функции ReLU является кусочно-постоянной функцией и также может быть вычислена крайне эффективно. Это приводит к тому, что количество необходимых вычислительных ресурсов для обучения нейронной сети с использованием ReLU оказывается значительно ниже, чем при использовании рассмотренных выше логистической функции или гиперболического тангенса. Необходимо также отметить, что использование ReLU не приводит к эффекту насыщения нейронов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRFnrOR16P7x"
      },
      "source": [
        "\n",
        "**Недостатки:**\n",
        "\n",
        "Иногда при использовании ReLU в качестве функции активации мы можем столкнуться с нежелательным эффектом отключения (\"умирания\") отдельных нейронов. Механизм данного явления связан с возможностью получения на выходе функции активации нулевого значения при широком диапазоне входных сигналов — любая отрицательная линейная комбинация входных значений с весами нейрона будет преобразована ReLU в ноль. Если при текущем обновлении весов нейрона изменение может оказаться слишком большим (например, при выборе слишком высокой скорости обучения), новая конфигурация весов нейрона будет при любых входных значениях приводить к отрицательной линейной комбинации и, как следствие, тождественно равной нулю активации рассматриваемого нейрона. Такой нейрон также тождественно обратит в ноль и проходящий через него локальный градиент при обучении сети методом обратного распространения ошибки, что сделает практически невозможным возвращение нейрона в \"рабочее\" состояние."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epFtzDJn6P7y"
      },
      "source": [
        "#### **Leaky ReLU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5ykAUHp6P7y"
      },
      "source": [
        "Leaky ReLU (ReLU с «утечкой», название также обусловлено электротехнической аналогией) является простейшей модификацией описанной выше ReLU, призванной исправить проблему \"умирания\" отдельных нейронов. В отличие от ReLU, данная функция не равна константе $0$ при всех отрицательных входных значениях, а реализует в этой области линейную зависимость с небольшим угловым коэффициентом (например, с угловым коэффициентом $10^{-2}$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4DxVOIu6P7y"
      },
      "source": [
        "$$LeakyReLU(x)=max(0.01x,x)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKnF6k6w6P7y"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/activation_function_leaky_relu.png\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zN9ZRLu6P7y"
      },
      "source": [
        "Производная Leaky ReLU:\n",
        "\n",
        "$$\\frac{d}{dx}LeakyReLU(x)=\\frac{d}{dx}max(0.01x,x)=\\begin{cases}\n",
        "\\frac{d}{dx}0.01x, &\\text{$x<0$} \\\\\n",
        "\\frac{d}{dx}x, &\\text{$x\\geq0$}\n",
        "\\end{cases}=\n",
        "\\begin{cases}\n",
        "0.01, &\\text{$x<0$} \\\\\n",
        "1, &\\text{$x\\geq0$}\n",
        "\\end{cases}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XpOyHfE6P7z"
      },
      "source": [
        "[Leaky ReLU в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html):\n",
        "```python\n",
        "torch.nn.LeakyReLU()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXPWLsug6P7z",
        "outputId": "18f710a1-6ee4-4d43-b605-56c06a515313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_values: tensor([-0.4339,  0.5280,  0.0247, -0.3896, -0.6111])\n",
            "activation_lrelu: tensor([-0.0043,  0.5280,  0.0247, -0.0039, -0.0061])\n"
          ]
        }
      ],
      "source": [
        "activation = nn.LeakyReLU(0.01)\n",
        "input_values = torch.randn(5)\n",
        "activation_lrelu = activation(input_values)\n",
        "print(f\"input_values: {input_values}\\nactivation_lrelu: {activation_lrelu}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbh6HFqg6P7z"
      },
      "source": [
        "**Достоинства**: Сохраняет достоинства ReLU, при этом не страдает от проблемы \"умирания\".\n",
        "\n",
        "**Недостатки**: Некоторые исследователи сообщают об успешном применении данной функции активации, но результаты не всегда стабильны."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMqBp2rl6P7z"
      },
      "source": [
        "####  **GELU (Gaussian Error Linear Unit)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxoVMOXe6P7z"
      },
      "source": [
        "Функция активации, используемая в трансформерах: Google BERT и OpenAI GPT-2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSUUe_UG6P70"
      },
      "source": [
        "$$GELU(x)=xP(X\\leq x)=x\\Phi(x)=x\\cdot \\frac{1}{2}[1+erf(\\frac{x}{\\sqrt{2}})]$$\n",
        "\n",
        "$$erf(x)=\\frac{2}{\\sqrt{\\pi}}\\int_0^xe^{-t^2}dt$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg8b5XUa6P70"
      },
      "source": [
        "На практике GELU может быть приблизительно вычислена так:\n",
        "$$GELU(x)\\approx 0.5x(1+tanh[\\sqrt{2/\\pi}(x+0.044715x^3)])$$\n",
        "\n",
        "или\n",
        "\n",
        "$$GELU(x) \\approx x\\cdot \\sigma(1.702x)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcJWPp396P70"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/activation_function_gelu.png\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3OG69206P71"
      },
      "source": [
        "**Достоинства**: State-of-the-art функция активации в задачах NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo5GTT-86P71",
        "outputId": "be2cf1d3-a9e2-4f94-df35-524d50423543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_values: tensor([ 7.6207,  4.4801,  4.4960, -6.8737, -6.4228])\n",
            "activation_gelu: tensor([7.6207, 4.4801, 4.4960, 0.0000, 0.0000])\n"
          ]
        }
      ],
      "source": [
        "activation = nn.GELU()\n",
        "input_values = torch.randn(5) * 5\n",
        "activation_gelu = activation(input_values)\n",
        "print(f\"input_values: {input_values}\\nactivation_gelu: {activation_gelu}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjwnRmz66P71"
      },
      "source": [
        "[GELU в PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.GELU.html):\n",
        "```python\n",
        "torch.nn.GELU()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1R_-27S6P72"
      },
      "source": [
        "### Визуализация функций активации:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmRy1Iau6P72"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L05/out/animated_activation_functions.png\" width=\"900\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORaeK5AI6P72"
      },
      "source": [
        "[How Activation Functions Work in Deep Learning](https://www.kdnuggets.com/2022/06/activation-functions-work-deep-learning.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCGBdnfW6P72"
      },
      "source": [
        "# Углубление в PyTorch. Пример нейронной сети на MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZP5Buro6P73"
      },
      "source": [
        "Источник: [Learn the basics tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9kWMhr56P73"
      },
      "source": [
        "## Dataset и DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI_rlY546P73"
      },
      "source": [
        "<img src=\"https://edunet.kea.su/repo/EduNet-content/L05/out/dataset_dataloader.png\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa8yDq2b6P74"
      },
      "source": [
        "Предварительная обработка данных часто сильно зависит от домена, предметной области, самих данных. В идеале мы бы хотели, чтобы код, относящийся к набору данных, был отделен от кода для обучения модели для его лучшей читаемости, понимаемости и модульности.\n",
        "\n",
        "PyTorch предоставляет два базовых класса для работы с данными: `torch.utils.data.DataLoader` и `torch.utils.data.Dataset`, которые позволяют работать как со встроенными наборами данных, так и с вашими собственными данными.\n",
        "\n",
        "`Dataset` хранит в себе объекты (samples, сэмплы) — например, изображения и соответствующие им метки (labels, targets).\n",
        "\n",
        "`DataLoader` представляет из себя итерируемый объект — обертку над `Dataset`-ом, и позволяет получить простой доступ к объектам и меткам из набора данных в виде мини-батчей.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC6KWg3G6P74"
      },
      "source": [
        "Библиотеки из семейства PyTorch предоставляют ряд предзагруженных наборов данных (например, таких как MNIST), которые релизованы как дочерние классы от `torch.utils.data.Dataset` и несут в себе функции, специфичные для конкретных данных. Эти наборы данных могут быть использованы как бенчмарк для отладки и оценки вашей модели или в учебных целях. Вы можете найти их здесь: [Image Datasets](https://pytorch.org/vision/stable/datasets.html), [Text Datasets](https://pytorch.org/text/stable/datasets.html), и [Audio Datasets](https://pytorch.org/audio/stable/datasets.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNZGAaG66P75"
      },
      "source": [
        "### Загрузка набора данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSG34R_66P75"
      },
      "source": [
        "Рассмотрим пример того, как загрузить набор данных MNIST, который содержится в [`torchvision.datasets`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST). MNIST содержит 60&nbsp;000 изображений для обучения и 10&nbsp;000 изображений для теста, размеченных на 10 классов — по числу цифр. Каждый пример представляет собой изображение размером 28×28 пикселей в оттенках серого. Каждое изображение имеет метку класса — то, какая цифра на нем изображена."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBFiTpWK6P75"
      },
      "source": [
        "Загрузим MNIST, указав следующие параметры:\n",
        "* `root` — это путь, куда будут скачаны данные,\n",
        "* `train` определяет, скачивать обучающую или тестовую часть набора данных,\n",
        "* `download=True` позволяет скачать данные из интернета, если их нет в пути `root`,\n",
        "*  `transform` определяет преобразования, которые нужно сделать с данными. Здесь мы сразу указываем `transform=ToTensor()`, чтобы перевести входные данные (изображения) в формат `torch.Tensor`. Подробнее о трансформациях поговорим далее."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvFPXlcs6P76",
        "outputId": "8b2b5a45-7262-40a4-b854-34a83de9c822"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data info:\n",
            " Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./MNIST\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "\n",
            "Test data info:\n",
            " Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./MNIST\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from IPython.display import clear_output\n",
        "\n",
        "train_data = datasets.MNIST(\n",
        "    root=\"./MNIST\", train=True, download=True, transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"./MNIST\", train=False, download=True, transform=ToTensor()\n",
        ")\n",
        "\n",
        "clear_output()\n",
        "\n",
        "print(\"Train data info:\\n\", train_data)\n",
        "print(\"\\nTest data info:\\n\", test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5_yQuV_6P76"
      },
      "source": [
        "### Итерирование по `Dataset` и визуализация данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3lEKBPE6P76"
      },
      "source": [
        "Можно обращаться к элементам `Dataset`-а вручную, как в списках или массивах: `dataset[i]`. При таком обращении мы получим кортеж `(sample, label)`. Воспользуемся matplotlib, чтобы отобразить первые 10 изображений из тестового множества."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "PrhHG2gZ6P76",
        "outputId": "7e9792ee-3ebd-42b8-853f-422de7d59902"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABiEAAACtCAYAAADWI9yPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApFklEQVR4nO3dedyWY94/8OMWKqJpJaNNyVKRJdEUNXqRKIwiGmNfHvvYIzKReR6MsWuaZ2yJiWxZpiFPiDRkyZOsmUoq2kRp7/798XuNZ87rOGfuq7vrvK97eb9fL398Px3XeX/L2XktR9f5LSktLS0NAAAAAAAABbZZsRsAAAAAAACqJ5sQAAAAAABAJmxCAAAAAAAAmbAJAQAAAAAAZMImBAAAAAAAkAmbEAAAAAAAQCZsQgAAAAAAAJmwCQEAAAAAAGTCJgQAAAAAAJAJmxAAAAAAAEAmbEKU4eSTTw4lJSX/8r+vvvqq2C1Szbz99tvhvPPOC+3btw9bb711aNGiRTj22GPDp59+WuzWqMaWL18ehg4dGnr37h0aNmwYSkpKwgMPPFDstqjmVq9eHa644oqwww47hLp164YuXbqEl156qdhtUcMMHz48lJSUhA4dOhS7Faopz7FUBq51VIR33nkn9O7dO2y77bZhm222CYccckh4//33i90W1dgrr7zyLz+vmzJlSrHbo5pyrSufzYvdQGV31llnhV69eiWy0tLScPbZZ4dWrVqFn/70p0XqjOrqv/7rv8Ibb7wRBgwYEPbYY4+wYMGCcNddd4W99947TJkyxRsHMrFo0aIwbNiw0KJFi7DnnnuGV155pdgtUQOcfPLJYezYseGiiy4KO++8c3jggQdCnz59wsSJE0O3bt2K3R41wNy5c8ONN94Ytt5662K3QjXmOZZic62jIrz77ruhW7duoXnz5mHo0KFhw4YN4Z577gkHHXRQeOutt8Iuu+xS7Bapxi644ILQuXPnRNa2bdsidUN15lpXfiWlpaWlxW6iqnn99ddD9+7dw/Dhw8NVV11V7HaoZiZPnhz23XffsOWWW/6YffbZZ6Fjx46hf//+4eGHHy5id1RXq1evDkuXLg3bb799mDp1aujcuXO4//77w8knn1zs1qim3nrrrdClS5dw8803h0svvTSEEMKqVatChw4dQtOmTcPkyZOL3CE1wcCBA8PChQvD+vXrw6JFi8L06dOL3RLVkOdYis21jopw+OGHhzfffDN89tlnoVGjRiGEEObPnx/atWsXDjnkkPDEE08UuUOqo1deeSX07NkzPP7446F///7FbocawLWu/NyOqRweeeSRUFJSEk444YRit0I11LVr18QGRAgh7LzzzqF9+/bho48+KlJXVHe1a9cO22+/fbHboAYZO3ZsqFWrVjjzzDN/zOrUqRNOO+208Oabb4Yvv/yyiN1RE7z22mth7Nix4bbbbit2K1RznmMpJtc6KsqkSZNCr169fvxQLoQQmjVrFg466KDw3HPPheXLlxexO2qC77//Pqxbt67YbVDNudaVn02IjbR27drw2GOPha5du4ZWrVoVux1qiNLS0vD111+Hxo0bF7sVgIJ47733Qrt27cK2226byPfbb78QQnBPTTK1fv36cP7554fTTz89dOzYsdjtAGTCtY6KtHr16lC3bt0o32qrrcKaNWt8A4dMnXLKKWHbbbcNderUCT179gxTp04tdktUU6515WcmxEb661//GhYvXhwGDRpU7FaoQUaPHh2++uqrMGzYsGK3AlAQ8+fPD82aNYvyf2Tz5s2r6JaoQUaMGBFmz54dJkyYUOxWADLjWkdF2mWXXcKUKVPC+vXrQ61atUIIIaxZsyb87W9/CyGE8NVXXxWzPaqpLbfcMhxzzDGhT58+oXHjxmHGjBnhlltuCd27dw+TJ08Oe+21V7FbpJpxrSs/34TYSI888kjYYostwrHHHlvsVqghPv7443DuueeGAw44IJx00knFbgegIFauXBlq164d5XXq1Pnx1yELixcvDtdee2245pprQpMmTYrdDkAmXOuoaOecc0749NNPw2mnnRZmzJgRpk+fHn71q1+F+fPnhxC8tiMbXbt2DWPHjg2nnnpq6NevX7jyyivDlClTQklJSRg8eHCx26Macq0rP5sQG2H58uXhmWeeCYceemji3l+QlQULFoTDDz881K9f/8f7pwNUB3Xr1g2rV6+O8lWrVv3465CFIUOGhIYNG4bzzz+/2K0AZMa1jop29tlnh6uuuio88sgjoX379qFjx45h5syZ4fLLLw8hhFCvXr0id0hN0bZt23DkkUeGiRMnhvXr1xe7HaoZ17ryswmxEZ5++unwww8/uBUTFWLZsmXhsMMOC99++20YP3582GGHHYrdEkDBNGvW7Md/LfLP/pG55pGFzz77LIwcOTJccMEFYd68eWHWrFlh1qxZYdWqVWHt2rVh1qxZYcmSJcVuE2CTuNZRLMOHDw9ff/11mDRpUvjggw/C22+/HTZs2BBCCKFdu3ZF7o6apHnz5mHNmjVhxYoVxW6Fasi1rnzMhNgIo0ePDvXq1Qv9+vUrditUc6tWrQp9+/YNn376aZgwYULYfffdi90SQEF16tQpTJw4MXz33XeJ4dT/uJdmp06ditQZ1dlXX30VNmzYEC644IJwwQUXRL/eunXrcOGFF4bbbrut4psDKBDXOoqpQYMGoVu3bj/WEyZMCDvuuGPYddddi9gVNc0XX3wR6tSp41+lkxnXuo1nEyJPCxcuDBMmTAjHH3982GqrrYrdDtXY+vXrw3HHHRfefPPN8Mwzz4QDDjig2C0BFFz//v3DLbfcEkaOHBkuvfTSEEIIq1evDvfff3/o0qVLaN68eZE7pDrq0KFDeOqpp6J8yJAh4fvvvw+33357aNOmTRE6Aygc1zoqizFjxoS333473HLLLWGzzdyIg8JbuHBhNPdm2rRpYdy4ceGwww5z3lEhXOvyYxMiT2PGjAnr1q1zKyYyd8kll4Rx48aFvn37hiVLloSHH3448eu//OUvi9QZ1d1dd90Vvv322zBv3rwQQgjPPvtsmDt3bgghhPPPPz/Ur1+/mO1RzXTp0iUMGDAgDB48OHzzzTehbdu24cEHHwyzZs0Kf/rTn4rdHtVU48aNw1FHHRXl//jXwGm/BoXgOZaK5FpHMbz22mth2LBh4ZBDDgmNGjUKU6ZMCffff3/o3bt3uPDCC4vdHtXUcccdF+rWrRu6du0amjZtGmbMmBFGjhwZttpqq/Cf//mfxW6Pasi1rvxKSktLS4vdRFVwwAEHhC+++CLMmzfPcGAy1aNHj/Dqq6/+y1/3V5astGrVKsyePTv11/7+97+HVq1aVWxDVHurVq0K11xzTXj44YfD0qVLwx577BGuv/76cOihhxa7NWqYHj16hEWLFoXp06cXuxWqKc+xVAaudWRp5syZ4Zxzzgnvvvtu+P7770Pr1q3DSSedFC6++OKw5ZZbFrs9qqk77rgjjB49Onz++efhu+++C02aNAkHH3xwGDp0aGjbtm2x26Macq0rP5sQAAAAAABAJtyoCgAAAAAAyIRNCAAAAAAAIBM2IQAAAAAAgEzYhAAAAAAAADJhEwIAAAAAAMiETQgAAAAAACATNiEAAAAAAIBMbJ7vwpKSkiz7oIopLS2tkJ/jvOOfVcR555zjn7nWUQzOO4rBcywVzbWOYnCto6K51lEMzjuKoazzzjchAAAAAACATNiEAAAAAAAAMmETAgAAAAAAyIRNCAAAAAAAIBM2IQAAAAAAgEzYhAAAAAAAADJhEwIAAAAAAMiETQgAAAAAACATNiEAAAAAAIBM2IQAAAAAAAAyYRMCAAAAAADIhE0IAAAAAAAgE5sXuwGori699NIoq1u3bpTtscceibp///55Hf/ee+9N1G+++Wa0ZtSoUXkdCwAAAAAgC74JAQAAAAAAZMImBAAAAAAAkAmbEAAAAAAAQCZsQgAAAAAAAJkoKS0tLc1rYUlJ1r1QheR52myyqnLejRkzJsryHTBdKDNnzoyyXr16RdmcOXMqop1MVMR5V1XOucqgXbt2Ufbxxx9H2YUXXhhld955ZyY9FZprXeFsvfXWifrmm2+O1px11llR9s477yTqAQMGRGtmz569id1VLs47isFzLBXNtY5icK2jornWVQ0NGjSIshYtWpTrWGnvTX79618n6unTp0drPv300yibNm1auXpw3lEMZZ13vgkBAAAAAABkwiYEAAAAAACQCZsQAAAAAABAJmxCAAAAAAAAmdi82A1AVZQ7iHpThlDnDvL961//Gq3Zaaedoqxv376Juk2bNtGaQYMGRdlvf/vbjW0RUu21115RtmHDhiibO3duRbRDJdesWbNEfcYZZ0Rr0s6fffbZJ1EfccQR0Zq77757E7ujqtl7772j7Mknn4yyVq1aVUA3/94hhxySqD/66KNozZdffllR7VBF5L7OCyGEcePGRdl5550XZSNGjEjU69evL1xjZKZp06ZR9thjj0XZ5MmTo2zkyJGJetasWQXrq5Dq168fZQceeGCiHj9+fLRm7dq1mfUEVH+HH354ou7Xr1+0pkePHlHWtm3bcv28tAHTLVu2TNS1a9fO61i1atUqVw9QGfkmBAAAAAAAkAmbEAAAAAAAQCZsQgAAAAAAAJkwEwLKsO+++0bZ0UcfXebjPvzwwyhLu/fgokWLEvXy5cujNVtuuWWUTZkyJVHvueee0ZpGjRqV2SeUV6dOnaJsxYoVUfbUU09VQDdUJk2aNImyBx98sAidUF0deuihUZbvvXUrWu69/U899dRozcCBAyuqHSqp3Nds99xzT16Pu+uuu6LsvvvuS9QrV64sf2NkpkGDBok67b1D2gyFr7/+Osoq4wyItN7feeedKMt9zZA7CyqEED7//PPCNcZG23bbbaMsd85ghw4dojW9evWKMvM92BS5czDPPffcaE3a3Lm6desm6pKSksI2lqNdu3aZHh+qKt+EAAAAAAAAMmETAgAAAAAAyIRNCAAAAAAAIBM2IQAAAAAAgExU2sHU/fv3j7K0ATPz5s1L1KtWrYrWjB49OsoWLFgQZQZekaZZs2ZRljvIKG2QXNrQzPnz55erh0suuSTKdt999zIf9/zzz5fr50Ga3IFz5513XrRm1KhRFdUOlcQFF1wQZUcddVSU7bfffgX5eQceeGCUbbZZ/G8qpk2bFmWvvfZaQXqgYm2+efxytU+fPkXopHxyB7FefPHF0Zqtt946ylasWJFZT1Q+ude2HXfcMa/HPfroo1GW9n6I4mrcuHGUjRkzJlE3bNgwWpM2oPz8888vXGMZGjJkSJS1bt06ys4666xE7T15cQ0aNCjKhg8fHmXNmzcv81hpA60XL15cvsYgxM+NF154YZE6+T8ff/xxlKV9PkT10bZt2yhLe54/+uijE3WPHj2iNRs2bIiyESNGRNkbb7yRqKvqc6VvQgAAAAAAAJmwCQEAAAAAAGTCJgQAAAAAAJAJmxAAAAAAAEAmKu1g6ptuuinKWrVqVa5j5Q67CiGE77//Psoq4/CYuXPnRlnan83UqVMrop0a6dlnn42y3EE0aefTkiVLCtbDwIEDo2yLLbYo2PEhH7vuumuiThukmjtkkerv97//fZSlDdgqlF/84hd5ZbNnz46y4447LlHnDgymcurZs2eUHXDAAVGW9vqoMmjQoEGi3n333aM1W221VZQZTF191a5dO8quvvrqch1r1KhRUVZaWlquY5GdvffeO8rSBlTmGjZsWAbdZKN9+/aJ+pJLLonWPPXUU1HmtWPx5A75DSGE2267LcoaNWoUZflcZ+68884oO++88xJ1Id8zUznlDuxNGyadO3Q3hBDGjx8fZatXr07Uy5Yti9akvX7Kfd/64osvRmumT58eZX/729+i7L333kvUK1euzKsHqoYOHTpEWe51K+29Z9pg6vLq0qVLlK1bty5Rf/LJJ9Ga119/Pcpy/76tWbNmE7vbNL4JAQAAAAAAZMImBAAAAAAAkAmbEAAAAAAAQCYq7UyIM844I8r22GOPKPvoo48S9W677RatyfcenPvvv3+i/vLLL6M1zZs3j7J85N6/K4QQFi5cGGXNmjUr81hz5syJMjMhKlbavcYL5bLLLouydu3alfm4tPsVpmVQXpdffnmiTvt74FpUvb3wwgtRttlm2f57hsWLFyfq5cuXR2tatmwZZa1bt46yt956K1HXqlVrE7sjC7n3Yn300UejNTNnzoyyG2+8MbOeNsWRRx5Z7BaoZDp27Bhl++yzT5mPS3s/8Ze//KUgPVE4TZs2jbJjjjmmzMeddtppUZb2frEyyJ3/EEIIEyZMKPNxaTMh0mbrUTEuvfTSKGvYsGHBjp87iyuEEHr37p2ohw8fHq1JmyVR7PuYk5+0mYG58xf23HPPaM3RRx+d1/GnTJmSqNM+65s1a1aUtWjRIlGnzV7NcqYdxZf2efK5554bZWnXrW233bbM43/11VdRNmnSpET997//PVqT+xlLCOlzC/fbb79EnXat7tOnT5RNmzYtUY8YMSJaU5F8EwIAAAAAAMiETQgAAAAAACATNiEAAAAAAIBM2IQAAAAAAAAyUWkHU7/88st5ZbnGjx+f1/EbNGgQZZ06dUrUacNAOnfunNfxc61atSrKPv300yjLHbSdNmwkbRgjVdcRRxyRqIcNGxat2XLLLaPsm2++SdSDBw+O1vzwww+b2B01VatWraJs3333TdRp17AVK1Zk1RJFcNBBByXqXXbZJVqTNsStvIPd0gZl5Q6zW7ZsWbTm5z//eZRdffXVZf68//iP/4iye++9t8zHka0hQ4Yk6rQhh7mDLUNIH1pe0dJet+X+PTL4kHyGFKfJvR5SOf3ud7+Lsl/+8pdRlvte8/HHH8+sp0Lr3r17lG233XaJ+oEHHojWPPzww1m1RB5atmyZqE855ZS8HvfBBx9E2ddff52oe/Xqldex6tevn6jThmOPHj06yhYsWJDX8ak4aZ9RPPLII1GWO4j6xhtvjNbkM9g+TdoQ6jRz5swp1/Gpuv7whz8k6rTh540bN87rWLmfRf/v//5vtOaqq66KsrTPgXN17do1ytLeo953332JOvfz6xDi63IIIdx9992J+oknnojWLFy4sKw2C8Y3IQAAAAAAgEzYhAAAAAAAADJhEwIAAAAAAMiETQgAAAAAACATlXYwddaWLl0aZRMnTizzcfkMx85X2lC63IHZaQNPxowZU7AeKL7cYb9pA57S5J4Hr776asF6gtxBqmkqcoAR2UsbRv7nP/85Uec7vCvN7NmzE3XaUKzf/OY3UfbDDz9s9LFDCOHMM8+MsiZNmiTqm266KVpTp06dKLvrrrsS9dq1a8vsifz0798/yvr06ZOoP//882jN1KlTM+tpU6QNRM8dRP3KK69Ea7799tuMOqIyOvDAA8tcs2bNmihLO7+ofEpLS6MsbSD9vHnzEnXa//OKVrdu3ShLG7Z5zjnnRFnu7/vUU08tXGMURO4g02222SZaM2nSpChLe1+Q+3rp+OOPj9aknTtt2rRJ1Ntvv3205plnnomyww47LMqWLFkSZWSnXr16iXrw4MHRmiOOOCLKFi1alKhvueWWaE0+r/chhPT3apdffnmUnX766Ym6pKQkWpP2eca9994bZTfffHOiXrFiRZl95qtRo0ZRVqtWrSi77rrrEvX48eOjNS1btixYX1nxTQgAAAAAACATNiEAAAAAAIBM2IQAAAAAAAAyYRMCAAAAAADIRI0dTF3RmjZtGmX33HNPlG22WXJfaNiwYdEaA5iqrqeffjrKDjnkkDIf99BDD0XZkCFDCtESpOrYsWOZa9KG+lJ1bb55/JKgvIOoX3311SgbOHBgos4dUrcp0gZT//a3v42yW2+9NVFvtdVW0Zq083rcuHGJeubMmRvbIv/CgAEDoiz3/0va66XKIG2Y+6BBg6Js/fr1ifqGG26I1hh2Xn117do1ryxX2tDD999/vxAtUUkcfvjhifrFF1+M1qQNrU8bmlleuQOHe/ToEa3Zf//98zrW2LFjC9ESGapdu3aiThui/vvf/z6vY61atSpR33///dGatOf4nXbaqcxjpw0prgyD22u6o446KlFfeeWV0Zo5c+ZEWffu3RP1smXLCtoXNUva89Rll10WZbmDqL/66qtozTHHHBNlb731Vvmby5E7YLp58+bRmrTP+l544YUoa9CgQZk/L2349qhRoxJ12uuKiuSbEAAAAAAAQCZsQgAAAAAAAJmwCQEAAAAAAGTCTIgKcu6550ZZkyZNomzp0qWJ+pNPPsmsJ7LVrFmzKEu7B3DuvTnT7pOedv/o5cuXb0J38H/S7vV7yimnRNl7772XqF966aXMeqLqmDp1apSdeuqpUVbIGRD5yJ3jEEJ8v/7OnTtXVDuEEOrXrx9l+dxrvJD3Py+kM888M8rS5qh89NFHiXrixImZ9UTlU97rTGU97ynb7bffHmU9e/aMsh122CFRH3jggdGatPs79+vXbxO6+/fHT5sRkOaLL76IsquuuqogPZGd448/vsw1ubNKQkifa5iPfffdt1yPmzJlSpR571t8+cwzyn2/GEIIc+fOzaIdaqjcOQshxPPX0qxbty7KunTpEmX9+/ePsl133bXM469cuTLKdtttt39bh5D+Hnm77bYr8+el+frrr6Ms97PEYs+h800IAAAAAAAgEzYhAAAAAACATNiEAAAAAAAAMmETAgAAAAAAyITB1Bn42c9+FmVXXnllXo896qijEvX06dML0RJF8MQTT0RZo0aNynzcww8/HGUzZ84sSE+QplevXlHWsGHDKBs/fnyiXrVqVWY9UTlstlnZ/1YhbaBXZZA2zDP395PP7y+EEK677rpEfeKJJ5a7r5qsdu3aUfbTn/40yh599NGKaGeTtWnTJq91XsvVbPkOZv32228TtcHUVdc777wTZXvssUeUderUKVH37t07WnPZZZdF2cKFC6PswQcf3IgO/8+oUaMS9bRp0/J63OTJk6PM+5XKL/f5NW3IeefOnaMsbShrx44dE/XRRx8drWnQoEGU5V7r0tacccYZUZZ7roYQwowZM6KM7KQN7M2Vdh0bOnRoon7mmWeiNe+//365+6Jm+Z//+Z8omzhxYpTlfsbRokWLaM0dd9wRZaWlpWX2kDYIO21gdj7yHUK9YcOGRP3UU09Fay644IIomz9/frn6yopvQgAAAAAAAJmwCQEAAAAAAGTCJgQAAAAAAJAJmxAAAAAAAEAmSkrzmboR0gc8km748OFRNnjw4Ch7+eWXo6xPnz6Jeu3atYVrrIDyPG02WVU579KGej322GNRtsUWW0TZK6+8kqiPPPLIaM3y5cvL31w1UhHnXVU55wrp8ccfj7JjjjmmzCxtGFJ1U5OudbfcckuUXXjhhWU+Lu26Vhmcf/75UXbrrbcm6rTB1LlDv0KIBzJmPXyzup53devWjbJJkyZFWe451bNnz2jNkiVLCtdYHpo2bRpl+Q56yx0Sd/fddxekp0LzHFsY3bp1S9SvvvpqtCbt2jN79uxE3apVq4L2VRlV12tdVbLTTjsl6s8//zxakzYw9tBDD42ytIHZlVFNvtY1bNgwUaf9/65fv36Upf1+8vlznDBhQpSde+65ifq5556L1uy8885R9sc//jHKzj777DJ7qAyqy7Uu9/eR9po5H2mPGzFiRJRNmTIlynKHC6edwx9++GGZPbRv3z7K3nzzzSibO3dumceqrKrLeVdeP/nJTxL1lVdeGa352c9+FmWLFy+Osjlz5iTq2rVrR2v23HPPKNtvv/3KajNvuX9HrrrqqmjNt99+W7CfV15lnXe+CQEAAAAAAGTCJgQAAAAAAJAJmxAAAAAAAEAmNi92A9VB7j2Oe/fuHa1Zs2ZNlA0dOjTKKusMCJIaNWqUqNPux5bvfdJz77Nq/gNZ23777RN19+7dozWffPJJlNWEGRA1Wd++fYvdQl6aNGkSZbvvvnuUpV2X85F2T2vPzYWxcuXKKEubr5E7f+b555+P1uTO99gUHTp0iLLc+6Sn3Z8/33vtlveeyVRNua8R0+Y/pHnppZeyaAf+rWuvvTZRp13XrrjiiiirKvMfSMqdp3TsscdGa8aOHRtlaXMict15551RlnburFq1KlE/+eST0Zq0e7enzSFp06ZNos56ZldNlzs/7uKLLy7XcdKeF88555y8siylXddy53eGEMLAgQMroBs2Ve58hLTrSiE99NBDUZbPTIjvv/8+ytL+bj3wwAOJev369fk3V4n4JgQAAAAAAJAJmxAAAAAAAEAmbEIAAAAAAACZsAkBAAAAAABkwmDqArjssssS9V577RWtGT9+fJRNnjw5s57I1iWXXJKoO3funNfjnn766ShLG1AOWTr55JMTddOmTaM1f/nLXyqoG9g4V199dZSde+655TrWrFmzouykk06Ksjlz5pTr+JQt7TmwpKQkUR9++OHRmkcffbRgPSxatCjKcoezNm7cuNzHzx0kR/XWv3//MtfkDksMIYQ//OEPGXQD/2fAgAFR9qtf/SpRpw3IXLx4cWY9UVwTJkyIsrRr2AknnBBludex3CHnIcRDqNNcf/31UbbbbrtFWb9+/aIs92emvYajcHIH+44ZMyZa88gjj0TZ5psnP3Zs3rx5tCZtWHVFa9KkSZSl/X0YMmRIor7hhhsy64nK6fLLL4+y8g4sP/vss6OskO9zKpvi/00HAAAAAACqJZsQAAAAAABAJmxCAAAAAAAAmbAJAQAAAAAAZMJg6o2UNhzxmmuuSdTfffddtGbYsGGZ9UTFu/jii8v1uPPOOy/Kli9fvqntwEZp2bJlmWuWLl1aAZ1A2V544YVEvcsuuxTs2DNmzIiy119/vWDHp2wff/xxlB177LGJulOnTtGatm3bFqyHsWPHlrnmwQcfjLJBgwbldfyVK1dudE9UDTvuuGOUpQ1wzTV37twomzp1akF6gn/lsMMOK3PNc889F2XvvvtuFu1QSaUNq07LCiXtOTJt4HHaYOqePXsm6oYNG0ZrlixZsgnd8c/Wr1+fqNOet9q1a1fmcQ4++OAo22KLLaLsuuuui7LOnTuXefxCKikpibJ99tmnQnug+E4//fREnTucPIR4AHuaDz/8MMqefPLJ8jdWBfkmBAAAAAAAkAmbEAAAAAAAQCZsQgAAAAAAAJmwCQEAAAAAAGTCYOp/o1GjRlF2xx13RFmtWrUSde4QzRBCmDJlSuEao8pKG5a1du3aghx72bJleR07behT/fr1yzz+T37ykygr74Du3KFWIYRwxRVXJOoffvihXMembEcccUSZa5599tkK6ITKJG3w2mablf1vFfIZdBlCCCNHjkzUO+ywQ16Py+1hw4YNeT0uH3379i3YscjO+++/n1eWpS+++KLcj+3QoUOinj59+qa2QyXRtWvXKMvnuvn0009n0A38e2nP1ytWrEjUv/vd7yqqHfiXHnvssShLG0x93HHHJerzzjsvWjNs2LDCNUZBvPzyy3mt69SpU5TlDqZet25dtOb++++Psj/+8Y+J+qKLLorWnHDCCXn1RfW23377RVnuc2O9evXyOtby5csT9dlnnx2tWb169UZ0V/X5JgQAAAAAAJAJmxAAAAAAAEAmbEIAAAAAAACZMBPin+TOdhg/fny0pnXr1lE2c+bMRH3NNdcUtjGqjQ8++CCzYz/++ONRNn/+/Cjbbrvtoiz3fprFsGDBgkQ9fPjwInVSvXTr1i3Ktt9++yJ0QmV37733RtlNN91U5uOee+65KMtnbkN5ZztsykyIESNGlPux1GxpM1PSsjRmQFRfafPjci1atCjKbr/99izagR+l3Xc67T3AN998k6jffffdzHqCfKW91kt7TXrkkUcm6qFDh0Zr/vznP0fZp59+ugndUVFefPHFKMv9jGDzzeOPNM8444woa9u2baLu0aNHufuaO3duuR9L5Zc2M3CbbbYp83G5M5ZCiGfZvPHGG+VvrJrwTQgAAAAAACATNiEAAAAAAIBM2IQAAAAAAAAyYRMCAAAAAADIhMHU/6RNmzaJep999snrcRdffHGizh1UTfXzwgsvJOrcoVjFMGDAgIIda926dVGWzzDYcePGRdnUqVPz+pmTJk3Kax0b5+ijj46yWrVqJer33nsvWvPaa69l1hOV05NPPhlll112WaJu0qRJRbXzLy1cuDDKPvrooyg788wzo2z+/PmZ9ET1V1pamldGzXLooYeWuWbOnDlRtmzZsizagR+lDaZOu2Y9//zzZR4rbSBngwYNoiztXIdCef/996Ps2muvTdQ333xztObGG2+MshNPPDFRr1y5ctOaIxNpr+8fe+yxRH3sscfmdayePXuWuWb9+vVRlnaNvPLKK/P6mVR+ac9vl19+ebmONXr06Ch75ZVXynWs6sw3IQAAAAAAgEzYhAAAAAAAADJhEwIAAAAAAMiETQgAAAAAACATNXYwdcuWLaPsxRdfLPNxuUM6QwjhueeeK0hPVB2/+MUvEnXa8JotttiiXMdu3759lB133HHlOtZ9990XZbNmzSrzcU888USUffzxx+XqgYqz1VZbRVmfPn3KfNzYsWOjLG0wF9Xb7Nmzo2zgwIGJ+qijjorWXHjhhVm1lGr48OFRdvfdd1doD9Q8derUyWud4ZbVV9rrujZt2pT5uFWrVkXZ2rVrC9ITbKrc13uDBg2K1vz617+Osg8//DDKTjrppMI1Bnl46KGHEvVZZ50Vrcl93x5CCMOGDUvUH3zwQWEboyDSXlNddNFFibpevXrRmn333TfKmjZtmqjTPhMZNWpUlF133XX/vkmqjLRzZcaMGVGWz+d4adeM3HOTdL4JAQAAAAAAZMImBAAAAAAAkAmbEAAAAAAAQCZKSktLS/NaWFKSdS8VKu2e0oMHDy7zcfvtt1+UTZ06tSA9VSV5njabrLqdd2yaijjvqvI5l3b/wldffTXKvvnmm0R9wgknRGt++OGHwjVWhbnWla13795RduaZZ0ZZ3759E/W4ceOiNSNHjoyy3D+btHt3zpkzp8w+qxLnXeWzYMGCKNt883i02vXXXx9lt99+eyY9FZrn2H+vVq1aUfbf//3fUXbyyScn6tx7lofg3vn/4FqXnffffz/KOnbsGGW5fzZp/0/+9Kc/RVnate7LL7/ciA6Lx7Wu+mrRokWUpd37/9FHH03UabNQCsm1rmKdeOKJUbb//vsn6t/85jfRmtz3yFWd8y6pX79+UfbMM89EWT5/bgcffHCUTZw4sXyNVTNl/fn5JgQAAAAAAJAJmxAAAAAAAEAmbEIAAAAAAACZsAkBAAAAAABkokYMpu7WrVuUvfDCC1FWr169Mo9lMPX/Z8gNxWCQHBXNtY5icN5VPs8++2yU3XrrrVFWlYfSeY7deDvssEOU3XDDDYn6nXfeidbcfffdmfVUlbjWZSft/e+wYcOi7LXXXkvU9957b7Rm6dKlUbZmzZpN6K64XOtqlhdffDHKDjjggETdpUuXaM2MGTMK1oNrHcXgvEuaNm1alHXs2DGvx958882J+oorrihIT9WRwdQAAAAAAEBR2IQAAAAAAAAyYRMCAAAAAADIhE0IAAAAAAAgE5sXu4GK0L179yjLZwj1zJkzo2z58uUF6QkAgKqhb9++xW6BSmjevHlRduqppxahE0h6/fXXo+znP/95ETqB4urfv3+U5Q6obdu2bbSmkIOpgeJr2LBhlKUN1f7mm2+i7LbbbsuipRrJNyEAAAAAAIBM2IQAAAAAAAAyYRMCAAAAAADIhE0IAAAAAAAgEzViMHW+cgcUHXzwwdGaJUuWVFQ7AAAAAJTDd999F2WtW7cuQidAMd166615Zddff32UzZ8/P5OeaiLfhAAAAAAAADJhEwIAAAAAAMiETQgAAAAAACATJaWlpaV5LSwpyboXqpA8T5tN5rzjn1XEeeec45+51lEMzjuKwXMsFc21jmJwraOiudZRDM47iqGs8843IQAAAAAAgEzYhAAAAAAAADJhEwIAAAAAAMiETQgAAAAAACATeQ+mBgAAAAAA2Bi+CQEAAAAAAGTCJgQAAAAAAJAJmxAAAAAAAEAmbEIAAAAAAACZsAkBAAAAAABkwiYEAAAAAACQCZsQAAAAAABAJmxCAAAAAAAAmbAJAQAAAAAAZOL/AYby/mRI/C/bAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_imgs_to_visualize = 10\n",
        "\n",
        "figure = plt.figure(figsize=(20, 20))\n",
        "\n",
        "for i in range(num_imgs_to_visualize):\n",
        "    # here we indexing the Dataset-object \"as is\" and gettig a tuple (img, label)\n",
        "    img, label = test_data[i]\n",
        "\n",
        "    figure.add_subplot(1, num_imgs_to_visualize, i + 1)\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRPoZFep6P77"
      },
      "source": [
        "### Подготовка данных для обучения с помощью DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-co3Xq56P77"
      },
      "source": [
        "`Dataset` возвращает по одной паре \"объект — метка\" за раз. При обучении моделей мы обычно хотим получать обекты в виде мини-батчей, перемешивая данные на каждой эпохе для уменьшения переобучения.\n",
        "\n",
        "`DataLoader` — это объект, который позволяет нам получать такие мини-батчи. При инициализации он принимает в себя объект `Dataset`, а также параметры `batch_size` (размер мини-батча) и `shuffle` (перемешивать ли данные в батчах каждую эпоху).\n",
        "\n",
        "Другие параметры, а также значения по умолчанию можно посмотреть в документации PyTorch для класса [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpWpEzqC6P77"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=8, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSXRqk0J6P78"
      },
      "source": [
        "Так как мы имели два объекта класса `Dataset`: `train_data` и `test_data`, то мы создаем также и два независимых `DataLoader`-а. Один из них позволит нам получать батчи из обучающей выборки, а другой — из тестовой.\n",
        "\n",
        "Обратите внимание на параметр `shuffle`! По умолчанию он имеет значение `False`. **Для обучения нейронной сети критически важно, чтобы во время обучения батчи обучающих данных перемешивались**. Именно таким образом мы вносим **стохастичность** в процесс градиентного спуска. Поэтому для `DataLoader`-a, который будет выдавать батчи для обучения, необходимо использовать `shuffle=True`.\n",
        "\n",
        "В противоположность этому — `DataLoader` для тестовых данных. Тестовые данные служат для оценки качества работы модели, на них не происходит обучение и градиентный спуск. Поэтому установка здесь `shuffle=True` не имеет большого смысла."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6CPykqJ6P78"
      },
      "source": [
        "### Итерирование по `DataLoader`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U08YEp_Q6P78"
      },
      "source": [
        "Мы загрузили набор данных в `DataLoader`, и теперь можем проходиться по нему по мере необходимости. Каждая итерация в коде ниже будет возвращать мини-батч в виде кортежа тензоров `(samples, labels)`, содержащих `batch_size=8` объектов и меток соответственно.\n",
        "Так как мы установили для `train_dataloader` параметр `shuffle=True`, когда мы пройдемся по всем батчам, данные перемешаются."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "JvxrhvQQ6P79",
        "outputId": "021239be-62c9-4b76-900f-429f6899ad16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images batch shape: torch.Size([8, 1, 28, 28]) : [batch_size, num_channels, H, W]\n",
            "Labels batch shape: torch.Size([8])\n",
            "\n",
            "The first sample in the batch:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# get one next batch\n",
        "imgs, labels = next(iter(train_dataloader))\n",
        "\n",
        "print(f\"Images batch shape: {imgs.size()} : [batch_size, num_channels, H, W]\")\n",
        "print(f\"Labels batch shape: {labels.size()}\")\n",
        "\n",
        "print(\"\\nThe first sample in the batch:\")\n",
        "img = imgs[0].squeeze()\n",
        "label = labels[0].item()\n",
        "\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.title(label)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JydFrrn6P79"
      },
      "source": [
        "## Трансформации (Transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhTGKVyW6P79"
      },
      "source": [
        "Данные не всегда поступают в том формате, который требуется для работы моделей машинного обучения. Для того, чтобы производить некоторые преобразования с данными и делать их пригодными для обучения, в PyTorch реализован механизм трансформаций (transforms).\n",
        "\n",
        "Все наборы данных в Torchvision имеют два параметра: `transform` — для применения трансформаций к входным данным, и `target_transform` — соответственно для преобразования меток.\n",
        "Эти параметры принимают в себя вызываемые (callable) объекты, содержащие логику преобразований. Модуль [`torchvision.transforms`](https://pytorch.org/vision/stable/transforms.html) предоставляет ряд часто используемых трансформаций \"из коробки\".\n",
        "\n",
        "Важно понимать, что трансформации, указанные в `transform` и `target_transform`, **применяются к данным налету**, то есть в момент обращения к этим данным через `Dataset` или `DataLoader`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r--ZQ-W6P7-"
      },
      "source": [
        "### ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JouCwQxd6P7-"
      },
      "source": [
        "Изображения в MNIST (и в большинстве других встроенных датасетов) изначально хранятся в формате PIL Image (Python Image Library), а метки представлены как целые числа. Если с метками, представленными таким образом, ничего делать не нужно, то входные данные для обучения необходимо перевести в тензоры. Чтобы произвести эту трансформацию, выше при загрузке данных MNIST мы использовали [`torchvision.transforms.ToTensor`](https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor).\n",
        "\n",
        "`ToTensor` преобразует PIL Image или NumPy `ndarray` в `FloatTensor` **и масштабирует значения интенсивности пикселей к диапазону $[0., 1.]$**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy04aUXT6P7-"
      },
      "source": [
        "### Normalize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUVXKKM06P7-"
      },
      "source": [
        "Предположим, что помимо перевода данных в подходящий формат мы бы хотели произвести какие-то преобразования с самими величинами. Скажем, произвести нормализацию: вычесть математическое ожидание и разделить на стандартное отклонение по выборке. Для проведения такой операции в `torchvision.transforms` предусмотрена трансформация [`Normalize`](https://pytorch.org/vision/main/generated/torchvision.transforms.Normalize.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi3pewAp6P7_"
      },
      "source": [
        "Два обязательных параметра в этой трансформации — это `mean` и `std`:\n",
        "* `mean` — последовательность математических ожиданий по каждому каналу выборки изображений,\n",
        "* `std` — последовательность стандартных отклонений по каждому каналу выборки изображений.\n",
        "\n",
        "`Normalize` не применяется к PIL Image, поэтому ее необходимо применять после `ToTensor`.\n",
        "\n",
        "Давайте вычислим среднее и стандартное отклонение для обучающей выборки MNIST. Для этого обратимся к `train_data.data`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdytOJRQ6P7_",
        "outputId": "484d174b-b95b-48f2-f4bf-fd7f4f3adf7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data.data:\n",
            "Type:  <class 'torch.Tensor'>\n",
            "Size:  torch.Size([60000, 28, 28])\n",
            "Dtype: torch.uint8\n",
            "Max:   255\n",
            "Min:   0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"train_data.data:\")\n",
        "print(\"Type: \", type(train_data.data))\n",
        "print(\"Size: \", train_data.data.size())\n",
        "print(\"Dtype:\", train_data.data.dtype)\n",
        "print(\"Max:  \", torch.max(train_data.data).item())\n",
        "print(\"Min:  \", torch.min(train_data.data).item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp-aL8Id6P8A"
      },
      "source": [
        "`train_data.data` — тензор целых чисел (`uint8`) c минимальным значением 0 и максимальным значением 255. Функции `torch.mean()` и `torch.std()` выдадут ошибку, если передать им тензор целых чисел. Поэтому изменим тип на вещественный, применив метод `.double()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRth-WSs6P8A",
        "outputId": "1ee4a1fc-9bf4-4024-9e04-744bb10c06a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean = 33.32, std = 78.57\n"
          ]
        }
      ],
      "source": [
        "mean = torch.mean(train_data.data.double()).item()\n",
        "std = torch.std(train_data.data.double()).item()\n",
        "print(f\"mean = {mean:.2f}, std = {std:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TecwTXDm6P8A"
      },
      "source": [
        "Вспомним, что `Normalize` должна применяться после `ToTensor`, которая масштабирует величины в диапазон $[0., 1.]$. Значит, матожидание и стандартное отклонение мы также должны разделить на максимальное значение до масштабирования — на 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeGWb3m16P8A",
        "outputId": "e1a85740-6013-4c0c-deee-6f240a782618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled mean = 0.13, std = 0.31\n"
          ]
        }
      ],
      "source": [
        "mean /= 255\n",
        "std /= 255\n",
        "print(f\"Scaled mean = {mean:.2f}, std = {std:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVH9qBuD6P8B"
      },
      "source": [
        "### Compose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im2fvixx6P8B"
      },
      "source": [
        "Мы вычислили среднее и стандартное отклонение по обучающей выборке MNIST для применения транcформации `Normalize`. Но мы также помним, что она должна применяться только после `ToTensor`. Как же объединить несколько трансформаций в одну, чтобы они применились последовательно?\n",
        "\n",
        "Для этого предусмотрен класс [`torchvision.transforms.Compose`](https://pytorch.org/vision/main/generated/torchvision.transforms.Compose.html). Его единственный параметр — список принимаемых трансформаций. `Compose` — это контейнер для трансформаций, при помещении в который они будут применяться поочерёдно. В общем случае их может быть сколько угодно. Давайте напишем трансформацию, которая примет в себя две: `ToTensor` и `Normalize`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k99SdzWZ6P8B",
        "outputId": "c12e8acd-2847-440a-bce6-6361fb47a07c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compose(\n",
            "    ToTensor()\n",
            "    Normalize(mean=0.1306604762738429, std=0.30810780717887876)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transform_with_normalize = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize(mean, std)]\n",
        ")\n",
        "\n",
        "print(transform_with_normalize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgDX1Dco6P8C"
      },
      "source": [
        "Остается только подменить у обучающего и тестового датасетов ту трансформацию, которую мы указали при загрузке данных, на нашу новую — с нормализацией. Для этого посмотрим на атрибут `.transform` и изменим его."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UMu9K4-6P8C",
        "outputId": "1d6399b0-b990-404e-bb2c-872c8aecac8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Old train transform: ToTensor()\n",
            "Old test transform: ToTensor()\n",
            "\n",
            "New train transform: Compose(\n",
            "    ToTensor()\n",
            "    Normalize(mean=0.1306604762738429, std=0.30810780717887876)\n",
            ")\n",
            "New test transform: Compose(\n",
            "    ToTensor()\n",
            "    Normalize(mean=0.1306604762738429, std=0.30810780717887876)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(\"Old train transform:\", train_data.transform)\n",
        "print(\"Old test transform:\", test_data.transform)\n",
        "\n",
        "train_data.transform = transform_with_normalize\n",
        "test_data.transform = transform_with_normalize\n",
        "\n",
        "print(\"\\nNew train transform:\", train_data.transform)\n",
        "print(\"New test transform:\", test_data.transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKietRo46P8C"
      },
      "source": [
        "Следует еще раз заметить, что при нормализации мы **вычисляем** оценки математического ожидания и стандартного отклонения `mean` и `std` **на обучающих данных**, а **применяем** вычисленные оценки **и на обучающих, и на тестовых данных**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePMaj3U16P8C"
      },
      "source": [
        "Теперь при обращении к данным через `DataLoader` будет происходить следующее:\n",
        "\n",
        "1. Объект `DataLoader` обращается к объекту `Dataset` за данными, чтобы сформировать батч.\n",
        "2. `Dataset` считывает данные, которые хранятся на диске, в формате PIL Image, применяет к ним трансформации, указанные в его атрибуте `.transform` (в данном случае это последовательность `ToTensor` и `Normalize`), и возвращает `DataLoader`-у преобразованные данные.\n",
        "3. `DataLoader` формирует из полученных данных батч и возвращает его."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV4B9-B26P8D"
      },
      "source": [
        "Обратите внимание, что на диске по-прежнему лежат просто изображения в своем специальном формате, и их довольно много. Но при этом в каждый момент времени мы не храним на диске все изображения как тензоры в сыром виде или в нормализованном. Нужные операции применяются к данным налету, только когда они нужны — при формировании батчей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwPdHNri6P8D"
      },
      "source": [
        "## Создание нейронной сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1dgh2LV6P8D"
      },
      "source": [
        "Нейронные сети состоят из слоев, которые производят преобразования над данными. В PyTorch принято называть слои ***модулями*** (modules), и далее мы тоже будем использовать это название.\n",
        "\n",
        "Пространство имен [`torch.nn`](https://pytorch.org/docs/stable/nn.html) предоставляет \"строительные блоки\", которые нужны для создания своей собственной нейронной сети. Каждый *модуль* в PyTorch является дочерним классом от [`nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). Таким образом, нейронная сеть сама по себе будет являться *модулем*, состоящим из других *модулей* (слоев). Такая вложенная структура позволяет легко создавать сложные архитектуры и управлять ими.\n",
        "\n",
        "Ниже мы рассмотрим пример создания нейронной сети для классификации изображений из набора данных MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pywfPTt6P8D"
      },
      "source": [
        "### Выбор устройства (device) для обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGl10u4m6P8D"
      },
      "source": [
        "Мы бы хотели иметь возможность обучать модель на аппаратном ускорителе, таком как GPU, если он доступен. Проверим, доступен ли нам ускоритель [`torch.cuda`](https://pytorch.org/docs/stable/notes/cuda.html), иначе продолжим вычисления на CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGeSMIeY6P8E",
        "outputId": "664fe97c-c623-437a-ebc7-9c3ab2d41123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OdmYU2w6P8E"
      },
      "source": [
        "### Описание класса модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESC9DIFT6P8E"
      },
      "source": [
        "Мы определяем нейронную сеть, наследуясь от класса `nn.Module`, и инициализируем ее слои в методе `__init__`. Каждый класс-наследник `nn.Module` производит операции над входными данными в методе `forward`.\n",
        "\n",
        "Напишем собственную нейронную сеть как класс `NeuralNetwork`. Ниже подробно рассмотрим все составляющие ее части."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUWdPpQx6P8E"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.layers_stack = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.layers_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omWhhdQH6P8E"
      },
      "source": [
        "Создадим экземпляр класса `NeuralNetwork`, переместим его на `device` с помощью метода `to` и выведем информацию о структуре модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAcmf3k56P8F",
        "outputId": "4d274f31-5907-49fb-a917-6e2bd19803d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (layers_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiNBxjLi6P8F"
      },
      "source": [
        "Чтобы использовать модель, мы передаем ей входные данные. Это приводит в действие метод `forward`, а также определенные фоновые операции. Не следует вызывать `model.forward` напрямую!\n",
        "\n",
        "Вызов модели с входными данными возвращает тензор с двумя размерностями: нулевая размерность `dim=0` соответствует  количеству переданных примеров, а первая `dim=1` — десяти выходным \"сырым\" предсказаниям (логитам) для каждого класса.\n",
        "\n",
        "Мы можем получить предсказание модели в виде вероятностей, пропустив логиты через экземпляр модуля `nn.Softmax`, вызвав его вычисление вдоль первой размерности `dim=1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KWzGr6m6P8F",
        "outputId": "7966a2d8-bd2f-4d3a-98f3-dcc4835fa2c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input size:       torch.Size([3, 1, 28, 28]) : [batch_size, num_channels, H, W]\n",
            "Output size:      torch.Size([3, 10])        : [batch_size, num_classes]\n",
            "Predicted class:  tensor([2, 2, 5])          : [class for sample 1, class for sample 2, class for sample 3]\n"
          ]
        }
      ],
      "source": [
        "# random input of 3 images\n",
        "sample_batch = torch.rand(\n",
        "    3, 1, 28, 28, device=device\n",
        ")  # [batch_size, num_channels, H, W]\n",
        "\n",
        "# model output\n",
        "logits = model(sample_batch)\n",
        "\n",
        "# predicted probabilities\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "\n",
        "# predicted classes\n",
        "y_pred = pred_probab.argmax(dim=1)\n",
        "\n",
        "print(f\"Input size:       {sample_batch.size()} : [batch_size, num_channels, H, W]\")\n",
        "print(f\"Output size:      {logits.size()}        : [batch_size, num_classes]\")\n",
        "print(\n",
        "    f\"Predicted class:  {y_pred}          : [class for sample 1, class for sample 2, class for sample 3]\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzuqoSfB6P8F"
      },
      "source": [
        "### Слои модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P2FMYwl6P8G"
      },
      "source": [
        "Давайте заглянем \"под капот\" нашей модели `NeuralNetwork`. Для иллюстрации возьмем мини-батч из трех одноканальных изображений 28×28 и посмотрим, что с ним происходит, когда мы пропускаем его через сеть."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-VSYT286P8G",
        "outputId": "5a985afb-8435-448f-fd08-3aa5b5aaf9bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input size: torch.Size([3, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "sample_batch = torch.rand(3, 1, 28, 28)\n",
        "print(f\"Input size: {sample_batch.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7V9PQmg6P8G"
      },
      "source": [
        "#### Слой `nn.Flatten`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXIEeHkc6P8G"
      },
      "source": [
        "Мы используем слой [`nn.Flatten`](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html) для преобразования каждого изображения 1×28×28 пикселей в непрерывный массив из 784 значений (размер батча (на позиции `dim=0`) сохраняется)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXA76bGX6P8G",
        "outputId": "54995470-5c96-49a1-89e2-77ba8aa0d6d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size after Flatten: torch.Size([3, 784])\n"
          ]
        }
      ],
      "source": [
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(sample_batch)\n",
        "print(f\"Size after Flatten: {flat_image.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW4fsrom6P8H"
      },
      "source": [
        "#### Слой `nn.Linear`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO0a9BtC6P8H"
      },
      "source": [
        "Линейный слой [`nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) — это модуль, который производит линейное преобразование входных данных с помощью хранящихся в нем весов и смещений.\n",
        "\n",
        "Обязательными параметрами при объявлении этого слоя являются `in_features` — количество входных признаков, и `out_features` — количество выходных признаков.\n",
        "\n",
        "Фактически, этот модуль добавляет в модель один полносвязный слой нейронов *без активаций*. Слой состоит из `out_features` нейронов, каждый из которых имеет `in_features` входов.\n",
        "\n",
        "В примере ниже мы объявляем слой из 512 нейронов, каждый из которых получает \"вытянутое\" изображение из 784 пикселей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USRPI4qE6P8H",
        "outputId": "fbbde4df-1827-4921-dae8-a281a6f93133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size after Linear:  torch.Size([3, 512])\n"
          ]
        }
      ],
      "source": [
        "layer1 = nn.Linear(in_features=784, out_features=512)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(f\"Size after Linear:  {hidden1.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NJwEJIa6P8H"
      },
      "source": [
        "Линейный слой, в отличие от слоя `nn.Flatten`, имеет обучаемые параметры — веса и смещения. Они хранятся как объекты специального класса `torch.nn.parameter.Parameter` и содержат в себе тензоры собственно с величинами параметров. Получить доступ к ним можно, обратившись к атрибутам слоя `.weight` и `.bias` соответственно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARjzS6J96P8H",
        "outputId": "c6fff32b-f974-47d8-b610-379be631c930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of linear layer weights: torch.Size([512, 784])\n",
            "Type of linear layer weights: <class 'torch.nn.parameter.Parameter'>\n",
            "\n",
            "Size of linear layer biases: torch.Size([512])\n",
            "Type of linear layer biases: <class 'torch.nn.parameter.Parameter'>\n"
          ]
        }
      ],
      "source": [
        "print(f\"Size of linear layer weights: {layer1.weight.size()}\")\n",
        "print(f\"Type of linear layer weights: {type(layer1.weight)}\")\n",
        "\n",
        "print(f\"\\nSize of linear layer biases: {layer1.bias.size()}\")\n",
        "print(f\"Type of linear layer biases: {type(layer1.bias)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8cPhXxJ6P8I"
      },
      "source": [
        "#### Слой `nn.ReLU`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLeHKet96P8I"
      },
      "source": [
        "Нелинейные активации — это то, что позволяет модели учить сложные взаимосвязи между входом и выходом. Они применяются после линейных преобразований, чтобы ввести *нелинейность*, помогая нейронным сетям изучать самые разные закономерности.\n",
        "\n",
        "В данной модели мы используем [`nn.ReLU`](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) между линейными слоями, но существуют и реализации [других функций активации](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pBGyYN26P8I",
        "outputId": "0da0e565-7c5d-4476-ebfe-a27ffad58a1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU:  tensor([[-0.0389, -0.2498, -0.1761,  ..., -0.4166,  0.1928, -0.2897],\n",
            "        [-0.2039, -0.3503, -0.0725,  ..., -0.0672,  0.2318, -0.0865],\n",
            "        [-0.0788, -0.8065, -0.2117,  ..., -0.2523,  0.2248, -0.4064]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "After ReLU:  tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1928, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2318, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2248, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n",
            "\n",
            " Size after ReLU:  torch.Size([3, 512])\n"
          ]
        }
      ],
      "source": [
        "activations1 = nn.ReLU()(hidden1)\n",
        "\n",
        "print(f\"Before ReLU:  {hidden1}\")\n",
        "print(f\"After ReLU:  {activations1}\")\n",
        "print(f\"\\n Size after ReLU:  {activations1.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qurJOGS76P8I"
      },
      "source": [
        "#### Объединение модулей в `nn.Sequential`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO1qtxOS6P8J"
      },
      "source": [
        "[`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) — это упорядоченный контейнер для модулей. Данные проходят через все модули в том же порядке, в котором они определены в `nn.Sequential`. Можно использовать такой контейнер для того, чтобы быстро собрать простую нейронную сеть, как `seq_modules` в примере ниже."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0cbfTgu6P8J",
        "outputId": "c5d55938-1ad4-4c64-9d4a-519114ced56f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output size: torch.Size([3, 10])\n"
          ]
        }
      ],
      "source": [
        "seq_modules = nn.Sequential(flatten, layer1, nn.ReLU(), nn.Linear(512, 10))\n",
        "\n",
        "sample_batch = torch.rand(3, 1, 28, 28)\n",
        "logits = seq_modules(sample_batch)\n",
        "\n",
        "print(f\"Output size: {logits.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIqZG-q26P8J"
      },
      "source": [
        "#### Слой `nn.Softmax`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5FNjPdA6P8J"
      },
      "source": [
        "Последний линейный слой нейронной сети возвращает *логиты* — \"сырые\" значения из диапазона $[-∞; +∞]$, которые могут быть пропущены через модуль [`nn.Softmax`](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html). Пропущенные через $\\text{sofmax}$ величины могут восприниматься как вероятности, с которыми модель относит данный объект к тому или иному классу. Параметр `dim` определяет размерность, вдоль которой величины должны суммироваться к $1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc_sw0dJ6P8K",
        "outputId": "89a5e7af-02c9-434a-df2b-a52565b244d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size after Softmax: torch.Size([3, 10])\n"
          ]
        }
      ],
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "pred_probab = softmax(logits)\n",
        "\n",
        "print(f\"Size after Softmax: {pred_probab.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_Xv5GaT6P8K"
      },
      "source": [
        "### Параметры модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAx5ZhNq6P8K"
      },
      "source": [
        "Множество слоев в нейронных сетях имеют *обучаемые параметры*, т. е. имеют ассоциированные с ними веса и смещения, которые оптимизируются во время обучения.\n",
        "\n",
        "Наследование от `nn.Module` автоматически отслеживает все слои, определенные внутри вашего класса модели, и делает все их параметры доступными с помощью методов `model.parameters()` или `model.named_parameters()`.\n",
        "\n",
        "В примере ниже мы проходимся по всем параметрам модели, и для каждого тензора параметров выводим его размер."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8kyxnDS6P8L",
        "outputId": "844c4d3d-f253-41d9-85a5-edf6525c7ad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (layers_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "Layer: layers_stack.0.weight      Size: torch.Size([512, 784])\n",
            "Layer: layers_stack.0.bias        Size: torch.Size([512])\n",
            "Layer: layers_stack.2.weight      Size: torch.Size([128, 512])\n",
            "Layer: layers_stack.2.bias        Size: torch.Size([128])\n",
            "Layer: layers_stack.4.weight      Size: torch.Size([10, 128])\n",
            "Layer: layers_stack.4.bias        Size: torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Model structure: {model}\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name:25}  Size: {param.size()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCNyKg-C6P8L"
      },
      "source": [
        "## Обучение нейронной сети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK4gweTo6P8L"
      },
      "source": [
        "Теперь, когда у нас есть данные и модель, настало время ее обучить, то есть оптимизировать ее параметры на обучающих данных.\n",
        "\n",
        "Обучение модели — итеративный процесс. На каждой итерции модель получает входные данные, дает предсказание на выходе, вычисляет значение функции потерь (loss), вычисляет производные функции потерь по параметрам и подстраивает параметры, используя градиентный спуск. Для более детального рассмотрения этого процесса рекомендуем посмотреть [видео об обратном распространении ошибки от 3Blue1Brown](https://www.youtube.com/watch?v=tIeHLnjs5U8).\n",
        "\n",
        "[Плейлист с видео о нейронных сетях от 3Blue1Brown с озвучкой на русском](https://www.youtube.com/playlist?list=PLfdZ2TeaMzfzlpZ60rbaYU_epH5XPNbWU)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7rcILvh6P8M"
      },
      "source": [
        "### Гиперпараметры"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKx_PG-P6P8M"
      },
      "source": [
        "Гиперпараметры — это задаваемые разработчиком параметры, которые позволяют управлять процессом обучения. Различные значения гиперпараметров могут влиять на обучение модели и скорость сходимости ([здесь](https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html) можно почитать подробнее про подбор гиперпараметров).\n",
        "\n",
        "Мы определим следующие гиперпараметры процедуры обучения:\n",
        "* **количество эпох** (`num_epochs`) — количество итераций обучения по всему набору данных;\n",
        "* **размер батча** (`batch_size`) — количество образцов, передаваемых в сеть для обновления параметров;\n",
        "* **скорость обучения** (`learning_rate`) — коэффициент, определяющий, насколько сильно нужно обновлять параметры модели на каждом батче. Малые значения приводят к долгому обучению, в то время как большие значения могут приводить к непредсказуемому поведению во время обучения.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IV_DtXDO6P8M"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq_EiSRF6P8M"
      },
      "source": [
        "Выше для демонстрации мы указывали размер батча в `DataLoader`-ах равным восьми. Для установки нового значения придется переопределить `DataLoader`-ы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyYLZ-gm6P8N"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xThW8Lpj6P8N"
      },
      "source": [
        "### Оптимизация параметров (обучение сети)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAaHfuhV6P8N"
      },
      "source": [
        "Задав гиперпараметры, мы можем приступить к обучению модели. Каждая итерация цикла оптимизации называется **эпохой**.\n",
        "\n",
        "Каждая эпоха состоит из двух частей:\n",
        "* **цикл обучения (Train Loop)** — проход по обучающему набору данных и оптимизация параметров;\n",
        "* **цикл валидации (Validation Loop)** — проход по валидационному/тестовому набору данных и контроль того, что качество работы сети улучшается.\n",
        "\n",
        "Кратко ознакомимся с некоторыми понятиями, используемыми в цикле оптимизации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGmxNiyH6P8N"
      },
      "source": [
        "#### Функция потерь (Loss function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XMB3rKQ6P8N"
      },
      "source": [
        "При получении некоторых обучающих данных наша необученная сеть, скорее всего, не даст правильного ответа. Функция потерь измеряет степень различия между значениями на выходе сети и целевыми значениями. Именно функцию потерь мы и хотим минимизировать во время обучения. Для вычисления функции потерь нужно получить предсказание модели, передав ей на вход пример из данных, и сравнить его с истинным значением целевой переменной.\n",
        "\n",
        "Наиболее часто применяемыми функциями потерь являются [`nn.MSELoss`](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss) (Mean Square Error) для задач регрессии и [`nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) для задач класиификации.\n",
        "\n",
        "\n",
        "Мы будем передавать выходы модели (логиты) в `nn.CrossEntropyLoss`, которая будет их нормализовывать и вычислять ошибку предсказания."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlvkYc8m6P8O"
      },
      "outputs": [],
      "source": [
        "# Initialize the loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp36mriI6P8O"
      },
      "source": [
        "#### Оптимизатор (Optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Agrgidz6P8O"
      },
      "source": [
        "Оптимизация — это процесс подстройки параметров модели для уменьшения ошибки на каждом шаге обучения. От **алгоритма оптимизации** зависит то, как этот процесс будет выполняться. Здесь мы будем использовать стохастический градиентный спуск (Stochastic Gradient Descent, SGD). Однако в PyTorch реализовано еще [множество других алгоритмов оптимизации](https://pytorch.org/docs/stable/optim.html#algorithms), таких как Adam и RMSProp, и они могут работать лучше или хуже для разных видов моделей и данных.\n",
        "\n",
        "Вся логика оптимизации заключена в объекте `optimizer`. Мы инициализируем оптимизатор, передавая ему параметры модели, которые требуется обучать (`model.parameters()`), а также гиперпараметр скорости обучения (`learning_rate`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsStYomr6P8O"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv8PLmBc6P8P"
      },
      "source": [
        "Внутри цикла обучения, оптимизация производится за три шага:\n",
        "1. Вызов `optimizer.zero_grad()`, чтобы сбросить градиенты параметров модели. По умолчанию градиенты суммируются, и во избежание повторного вычисления их необходимо явно обнулять на каждой итерации;\n",
        "2. Обратное распространение ошибки предсказания с помощью вызова `loss.backward()`. PyTorch вычислит градиенты функции потерь относительно каждого обучаемого параметра;\n",
        "3. Когда у нас есть градиенты, мы вызываем `optimizer.step()`, чтобы подстроить обучаемые параметры с учетом градиентов, посчитанных при обратном распространении, согласно алгоритму оптимизации.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9VD06nA6P8P"
      },
      "source": [
        "### Реализация обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm_8AJGa6P8P"
      },
      "source": [
        "Мы определим две функции:\n",
        "* `train_loop`, которая производит цикл обучения,\n",
        "* `test_loop`, которая оценивает качество модели на тестовых данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9s8Q09E6P8P"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, criterion, optimizer):\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    train_loss = 0\n",
        "\n",
        "    for imgs, labels in dataloader:\n",
        "        # Compute prediction and loss\n",
        "        pred = model(imgs.to(device))\n",
        "        loss = criterion(pred, labels.to(device))\n",
        "\n",
        "        # Optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= num_batches\n",
        "    print(f\"Train loss: {train_loss:>8f}\")\n",
        "\n",
        "    return train_loss\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, criterion):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in dataloader:\n",
        "            # Compute prediction and loss\n",
        "            pred = model(imgs.to(device))\n",
        "            loss = criterion(pred, labels.to(device))\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            correct += (\n",
        "                (pred.argmax(1) == labels.to(device)).type(torch.float).sum().item()\n",
        "            )\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test loss: {test_loss:>8f}, test accuracy: {(100*correct):>0.1f}% \\n\")\n",
        "\n",
        "    return test_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ76knya6P8Q"
      },
      "source": [
        "Выше мы объявили гиперпараметры и инициализировали функцию потерь `criterion` и оптимизатор `optimizer`. Теперь мы запускаем цикл оптимизации на 10 эпох, и в каждой итерации мы вызываем функцию для выполнения цикла обучения `train_loop`, а затем функцию для промежуточной оценки качества `test_loop`. Также на каждой эпохе будем сохранять текущее значение функции потерь на обучающих и тестовых данных для построения графика обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_06Tu2UR6P8Q",
        "outputId": "3bcaa348-e7b5-4bb2-c662-2797bfcc4352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Train loss: 2.106566\n",
            "Test loss: 1.831486, test accuracy: 59.2% \n",
            "\n",
            "Epoch 2\n",
            "Train loss: 1.461331\n",
            "Test loss: 1.074189, test accuracy: 78.3% \n",
            "\n",
            "Epoch 3\n",
            "Train loss: 0.866346\n",
            "Test loss: 0.680543, test accuracy: 85.0% \n",
            "\n",
            "Epoch 4\n",
            "Train loss: 0.612728\n",
            "Test loss: 0.526267, test accuracy: 87.1% \n",
            "\n",
            "Epoch 5\n",
            "Train loss: 0.502017\n",
            "Test loss: 0.449729, test accuracy: 88.4% \n",
            "\n",
            "Epoch 6\n",
            "Train loss: 0.441393\n",
            "Test loss: 0.402655, test accuracy: 89.3% \n",
            "\n",
            "Epoch 7\n",
            "Train loss: 0.403235\n",
            "Test loss: 0.372686, test accuracy: 89.8% \n",
            "\n",
            "Epoch 8\n",
            "Train loss: 0.376599\n",
            "Test loss: 0.350699, test accuracy: 90.3% \n",
            "\n",
            "Epoch 9\n",
            "Train loss: 0.357129\n",
            "Test loss: 0.334682, test accuracy: 90.5% \n",
            "\n",
            "Epoch 10\n",
            "Train loss: 0.341411\n",
            "Test loss: 0.320629, test accuracy: 90.7% \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# for plotting\n",
        "loss_history = {\"train\": [], \"test\": []}\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    print(f\"Epoch {i+1}\")\n",
        "    train_loss = train_loop(train_dataloader, model, criterion, optimizer)\n",
        "    test_loss = test_loop(test_dataloader, model, criterion)\n",
        "\n",
        "    loss_history[\"train\"].append(train_loss)\n",
        "    loss_history[\"test\"].append(test_loss)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeBMP81G6P8Q"
      },
      "source": [
        "Построим график функции потерь на обучающих и на тестовых данных по эпохам:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "3JpU7ayz6P8U",
        "outputId": "b2262c8b-833f-452e-8937-67d59f93b91f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, num_epochs + 1), loss_history[\"train\"], label=\"train\")\n",
        "plt.plot(range(1, num_epochs + 1), loss_history[\"test\"], label=\"test\")\n",
        "plt.xlabel(\"Epochs\", fontsize=15)\n",
        "plt.ylabel(\"Loss\", fontsize=15)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT7Fx7Vy6P8U"
      },
      "source": [
        "###  Посмотрим на предсказания обученной модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwvT9e_36P8U"
      },
      "source": [
        "Поэтапно пропустим тестовые изображения через модель и визуализируем результат"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv5mLsQ06P8V",
        "outputId": "e44cfcc2-82fd-4770-c37d-088ca2af1af0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imgs shape:  torch.Size([64, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# get batch\n",
        "imgs, labels = next(iter(test_dataloader))\n",
        "print(\"imgs shape: \", imgs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tqlU_6v6P8V",
        "outputId": "d5ea3337-93e7-4e9f-caa4-c62ae1cc59fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pred shape:  torch.Size([64, 10])\n"
          ]
        }
      ],
      "source": [
        "# get output\n",
        "pred = model(imgs.to(device))\n",
        "print(\"pred shape: \", pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXfzifpF6P8V",
        "outputId": "f57762ec-ea3d-489a-b622-368206716203"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.1069, -3.1941, -0.2074,  2.4022, -2.1309, -0.7126, -6.1349,  9.2594,\n",
              "        -1.9366,  3.8227], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "# First sample in prediction batch\n",
        "pred[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7NAZOuF6P8V",
        "outputId": "0ddc29ff-d60b-4739-bc04-5f3a84a770a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0535e-04, 3.8820e-06, 7.6942e-05, 1.0459e-03, 1.1240e-05, 4.6426e-05,\n",
              "        2.0506e-07, 9.9437e-01, 1.3651e-05, 4.3292e-03])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# Calculate probabilities\n",
        "nn.Softmax(dim=0)(pred[0].detach())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jisIzd9C6P8V",
        "outputId": "fd95dc1e-376f-42eb-95d0-d4312a35d2f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imgs shape(after reshape):  torch.Size([64, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# remove axis\n",
        "imgs = torch.reshape(imgs, (64, 28, 28))\n",
        "print(\"imgs shape(after reshape): \", imgs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df3nMVdc6P8V",
        "outputId": "b0ebb886-7b39-4465-c9e8-9e69eefe9e71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imgs shape:  torch.Size([10, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# take 10 first images\n",
        "imgs = imgs[:10]\n",
        "print(\"imgs shape: \", imgs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXtj81656P8V",
        "outputId": "8380d4f4-92fc-4da7-f3c9-d5713139a20e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction(1 sample):\n",
            " tensor([ 0.1069, -3.1941, -0.2074,  2.4022, -2.1309, -0.7126, -6.1349,  9.2594,\n",
            "        -1.9366,  3.8227])\n",
            "Predicted class:  7\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "pred = pred[:10].detach()\n",
        "print(\"Prediction(1 sample):\\n\", pred[0])\n",
        "digits = np.argmax(pred.cpu().numpy(), axis=1)\n",
        "print(\"Predicted class: \", digits[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfyJ9Aa26P8W"
      },
      "source": [
        "Визуализируем изображения, подпишем предсказанное и истинное значение:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "mcAmWUHM6P8W",
        "outputId": "3d6565fa-ae90-457c-8c3d-457ca6a48e8c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2500x2500 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAB6UAAADOCAYAAAB2I9fAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+80lEQVR4nO3deZzNdf//8deZpbEvM2O9YgaTrKWszZWGiwtZJjKWqLhIfBGVJaTGJXJ9Uy4tlpQUKTSWJBdSUyhyIWQZajImIuvI2Gb7/P7wM9+O8zqcz3E+c5Z53G+3brd6zue8P6/PdF7n8znnNeccm2EYhgAAAAAAAAAAAAAAYIEgbxcAAAAAAAAAAAAAAAhcDKUBAAAAAAAAAAAAAJZhKA0AAAAAAAAAAAAAsAxDaQAAAAAAAAAAAACAZRhKAwAAAAAAAAAAAAAsw1AaAAAAAAAAAAAAAGAZhtIAAAAAAAAAAAAAAMswlAYAAAAAAAAAAAAAWIahNAAAAAAAAAAAAADAMgyl/+Trr78Wm80mX3/9tbdLsZzNZpMJEyZ4uwz4uMLUE9HR0dK3b19vlwEfR08A9gpTT3DtBFfQE4C9wtQTXDvBVYWpLzhXwBX0BGCPngDs0ROBhaG0B0VHR4vNZlP/ueOOO7xdnsf07dvX6XHabDY5evSot0uEj1i2bJn06NFDqlevLsWKFZM777xTRowYIRkZGd4uzaNSUlJk9OjR0qBBAylZsqRUqlRJOnToINu2bfN2afAxBw4ckGeeeUZiY2OlSJEiYrPZJC0tzdtlWWLy5MkSHx8vFSpUKBQXVHDf0aNHpXv37lKmTBkpVaqUPPTQQ/LLL794uyyPu3Llijz33HNSuXJlKVq0qDRt2lS++OILb5cFH/f3v/9dbDabDB061NulWGry5Mlis9mkXr163i4FPoZrJ+DmOFcAIosWLZJ7771XihQpIuXKlZP+/fvLqVOnvF2Wx23fvl3atWsnpUqVkpIlS0qbNm1k586d3i4LPmrx4sVy3333SfHixaVMmTISGxsrX331lbfL8phrg0rtny1btni7PPgYzhO+I8TbBQSS6dOnS2Zmpl12+PBhGT9+vLRp08ZLVXnewIEDpXXr1naZYRgyaNAgiY6Olr/85S9eqgy+5sknn5TKlSvLo48+KlWrVpUff/xR3nrrLVm9erXs2LFDihYt6u0SPeLdd9+VuXPnSteuXWXw4MFy7tw5efvtt6VZs2ayZs0ah35B4bV582Z54403pE6dOlK7dm2fuyjwpPHjx0vFihXlnnvukbVr13q7HPiozMxMadmypZw7d07GjRsnoaGh8u9//1vi4uJk586dEhER4e0SPaZv376SlJQkTz/9tNxxxx3y/vvvS/v27SU5OVnuv/9+b5cHH7Rs2TLZvHmzt8uw3JEjR+Tll1+W4sWLe7sU+CCunYAb41wBiMyaNUsGDx4srVq1kmnTpsmRI0fk9ddfl23btsn3338vRYoU8XaJHrFjxw65//77pUqVKpKYmCh5eXkyc+ZMiYuLk61bt8qdd97p7RLhQyZMmCATJ06UhIQE6du3r2RnZ8uePXsC8s1kw4YNk8aNG9tlMTExXqoGvojzhG+dJwJiKJ2XlydZWVlev/N07tzZIZs0aZKIiPTu3dv0er5yXNe777775L777rPLNm3aJBcvXnTrOOF5vnLfSUpKkhYtWthlDRs2lD59+sjChQvliSeeMLWeYRhy+fJlnxtmP/LIIzJhwgQpUaJEftavXz+pXbu2TJgwgaG0D/CVnoiPj5eMjAwpWbKkvPrqq7f8wqqv9oSIyKFDhyQ6OlpOnTol5cqV83Y5uI6v9MTMmTPlp59+kq1bt+Y/iXzwwQelXr168tprr8nLL79saj1fOa7rbd26VRYtWiRTp06VkSNHiojI448/LvXq1ZPRo0fLd9995+UK4Wv3ncuXL8uIESPkueeekxdffNHtdXztuDQjR46UZs2aSW5ubkD+pbq/8pX7DtdO8CW+0hfXcK6At/nCfScrK0vGjRsnDzzwgHzxxRdis9lERCQ2NlY6deok77zzjjz11FOm1vSF49K88MILUrRoUdm8eXP+H+8++uijUrNmTRk3bpwsXbrUyxXCV+47W7ZskYkTJ8prr70mzzzzzC2v5yvH5Uzz5s0lISHB22VA4Qv3Hc4Tvnee8JmP754wYYLYbDZJSUmR7t27S6lSpSQiIkKGDx8uly9fttv22scSLVy4UOrWrSthYWGyZs0aEbn6EZD9+vWTChUqSFhYmNStW1fee+89h/0dOXJEOnfuLMWLF5fy5cvLM888I1euXHHY7uLFi5KSkuL2Re9HH30k1apVk9jY2Jtue6vHlZWVJS+++KI0bNhQSpcuLcWLF5fmzZtLcnKyS7WmpKRIenq6+YOUq8dps9mkV69ebt0ejgKhJ64fSIuIdOnSRURE9u/ff9PbR0dHS8eOHWXt2rXSqFEjKVq0qLz99tsiIpKRkSFPP/20VKlSRcLCwiQmJkb+93//V/Ly8uzWePXVVyU2NlYiIiKkaNGi0rBhQ0lKSrrpvkVEUlNTJTU19abbNWzY0G4gLSISEREhzZs3d+k44ZpA6Inw8HApWbKkm78B/+mJa7XCWoHQE0lJSdK4cWO7v2quVauWtGrVSpYsWXLT2/vLtVNSUpIEBwfLk08+mZ8VKVJE+vfvL5s3b5Zff/3Vpf3hxgKhJ6555ZVXJC8vL/+PGFzlLz1xzYYNGyQpKUmmT5/u8m3gukDoCa6d4GmB0BfXcK6AJ/h7T+zZs0cyMjKkR48e+YMGEZGOHTtKiRIlZNGiRTf9HfhLT2zcuFFat25t92lSlSpVkri4OFm1apXDp3fCPf7eEyJXP821YsWKMnz4cDEMw/R9w1964s/Onz8vOTk5pm4D1/h7T3Ce8L3zhM+9U7p79+4SHR0tU6ZMkS1btsgbb7whZ8+elfnz59tt99VXX8mSJUtk6NChEhkZKdHR0fL7779Ls2bN8u8k5cqVk//85z/Sv39/+eOPP+Tpp58WEZFLly5Jq1atJD09XYYNGyaVK1eWBQsWqN+psHXrVmnZsqUkJiaa/k6nH374Qfbv3y/PP/+8y7e5leP6448/5N1335VHHnlEBgwYIOfPn5e5c+dK27ZtZevWrdKgQYMb7rt27doSFxdn+gvjs7OzZcmSJRIbG8sTaQsEUk+IiBw/flxERCIjI13a/sCBA/LII4/IwIEDZcCAAXLnnXfKxYsXJS4uTo4ePSoDBw6UqlWrynfffSdjx46VY8eO2T1Zff311yU+Pl569+4tWVlZsmjRIunWrZusWrVKOnTocMN9t2rVSkTE7e+tO378uMvHCdcFWk+Y5c89AWv4a0/k5eXJ7t27pV+/fg4/a9Kkiaxbt07Onz9/02GEP1w7/fDDD1KzZk0pVaqUw3GKiOzcuVOqVKlywzXgOn/tiWvS09PlX//6l7z33ntuvZvTH3pCRCQ3N1eeeuopeeKJJ6R+/fqmjxOu8/eeuFVcO0Hj733BuQKe5q89cW1QofVB0aJF5YcffpC8vDwJCrrx+7L8oSeuXLmiHmexYsUkKytL9uzZI82aNbvhGnCdv/aEiMiXX34psbGx8sYbb8ikSZPk9OnTUrFiRXn++edl6NChLh2/P/TENf/4xz8kMzNTgoODpXnz5jJ16lRp1KiRS7eF6/y1JzhP+OB5wvARiYmJhogY8fHxdvngwYMNETF27dqVn4mIERQUZOzdu9du2/79+xuVKlUyTp06ZZf37NnTKF26tHHx4kXDMAxj+vTphogYS5Ysyd/mwoULRkxMjCEiRnJycn6enJxsiIiRmJho+phGjBhhiIixb98+l7a/1ePKyckxrly5YrfN2bNnjQoVKhj9+vVz2Nf1xyQiRlxcnEu1/tlnn31miIgxc+ZM07eFc4HYE9dqCg4ONg4ePHjTbaOiogwRMdasWWOXv/TSS0bx4sUd1hgzZowRHBxspKen52fXjvGarKwso169esbf/vY3h3316dPHIYuKinLhqBxt2LDBsNlsxgsvvODW7eEo0Hpi6tSphogYhw4dcvk2/tgTJ0+evKXHDDjn7z1x7b4xceJEh5/NmDHDEBEjJSXlhmv4y7VT3bp1HXrMMAxj7969hogYs2fPvukauDl/74lrEhISjNjYWLtahwwZ4tJt/aUnDMMw3nrrLaN06dLGiRMnDMMwjLi4OKNu3bou3RauCZSeuIZrJ3hCoPQF5wp4ir/3xMmTJw2bzWb079/fLk9JSTFExBARh7qu5y89Ub9+faNmzZpGTk5OfnblyhWjatWqhogYSUlJN10DN+fvPXHmzBlDRIyIiAijRIkSxtSpU43Fixcb7dq1c/m5p7/0xLfffmt07drVmDt3rvHpp58aU6ZMMSIiIowiRYoYO3bsuOnt4Rp/7wnOE753nvCZj+++ZsiQIXb/fe3z3FevXm2Xx8XFSZ06dfL/2zAMWbp0qXTq1EkMw5BTp07l/9O2bVs5d+6c7NixI3+tSpUq2X3XQLFixew+UvGaFi1aiGEYpv+COy8vTxYtWiT33HOP1K5d2+Xb3cpxBQcHy2233Za//zNnzkhOTo40atQof5sbMQzD9LukRa5+dHdoaKh0797d9G1xc4HSEyJX7ytz586VESNGyB133OHSbapVqyZt27a1yz755BNp3ry5lC1b1u64WrduLbm5ubJhw4b8bf/810Fnz56Vc+fOSfPmzV3qibS0NLfe1XDixAnp1auXVKtWTUaPHm369rixQOoJd/hjT8Ba/toTly5dEhGRsLAwh59d+16ea9vciD9cO126dOmWjxOu89eeEBFJTk6WpUuX3tJHlPpDT5w+fVpefPFFeeGFF/ju3ALgzz3hCVw7QePPfcG5Albw156IjIyU7t27ywcffCCvvfaa/PLLL7Jx40bp0aOHhIaGikjgPKcYPHiwHDx4UPr37y/79u2TPXv2yOOPPy7Hjh1z+TjhOn/tiWsfz3v69Gl59913ZeTIkdK9e3f5/PPPpU6dOjJp0iSXjt8feiI2NlaSkpKkX79+Eh8fL2PGjJEtW7aIzWaTsWPHunSccJ2/9gTnCd87T/jcx3dfP6iqUaOGBAUFOTyRq1atmt1/nzx5UjIyMmTOnDkyZ84cde0TJ06IiMjhw4clJibG7jPkRUTuvPPOW6z+/3zzzTdy9OhReeaZZ0zd7laOS0TymyslJUWys7OdruspmZmZ8umnn0rbtm3tPqsenhMoPbFx40bp37+/tG3bViZPnuzy7bT77k8//SS7d+92+sT0zz2xatUqmTRpkuzcudPu+yeuP1ZPuXDhgnTs2FHOnz8vmzZtcviuady6QOkJd/lbT8B6/toT117k174b6Nr3ErnycZT+cO1UtGjRWz5OuM5feyInJ0eGDRsmjz32mN33rJvlDz0xfvx4CQ8Pz38hA9by157wFK6doPHXvuBcAav4a0+IiLz99tty6dIlGTlyZP53rD/66KNSo0YNWbZsmUuvy/hDTwwaNEh+/fVXmTp1qnzwwQciItKoUSMZPXq0TJ48mdefPMxfe+Lac8vQ0FC7wV5QUJD06NFDEhMTJT09XapWrXrDdfyhJzQxMTHy0EMPybJlyyQ3N1eCg4Mt3V9h4q89IcJ5wtfOEz43lL6esyd61794l5eXJyJX70x9+vRRb3PXXXd5trgbWLhwoQQFBckjjzxi6na3clwffvih9O3bVzp37iyjRo2S8uXLS3BwsEyZMkVSU1PdOIqbW7FihVy8eFF69+5tyfpw5I89sWvXLomPj5d69epJUlKShIS4/tCjvVCfl5cnf//7352+C7lmzZoicnUQHh8fLw888IDMnDlTKlWqJKGhoTJv3jz56KOP3DuYG8jKypKHH35Ydu/eLWvXrpV69ep5fB9w5I89cSv8qSfgHf7SE+Hh4RIWFpb/F5t/di2rXLnyTdfxh2unSpUqydGjRx1yM8cJ9/lLT8yfP18OHDggb7/9tsMT+/Pnz0taWpqUL19eihUrdsN1fL0nfvrpJ5kzZ45Mnz5dfvvtt/z88uXLkp2dLWlpaVKqVCkJDw/3yP7gyF96wlO4doIr/KUvOFdwrigo/tITIiKlS5eWTz/9VNLT0yUtLU2ioqIkKipKYmNjpVy5clKmTJmbruHrPXHN5MmTZeTIkbJ3714pXbq01K9fX8aNGyci/3fugjX8pSfCw8OlSJEiUqZMGYeBbPny5UXk6ie/3Gwo7S89oalSpYpkZWXJhQsXpFSpUpbvr7Dyl54Q4Tzha+cJnxtK//TTT3Z/HfDzzz9LXl6eREdH3/B25cqVk5IlS0pubq60bt36httGRUXJnj17xDAMu+Y5cODALdV+zZUrV2Tp0qXSokWLW36R0cxxJSUlSfXq1WXZsmV2x5WYmHhLNdzIwoULpUSJEhIfH2/ZPgo7f++J1NRUadeunZQvX15Wr17tkb/IqVGjhmRmZt70uJYuXSpFihSRtWvX2n1s6rx58265huvl5eXJ448/Ll9++aUsWbJE4uLiPL4PXOXvPWEFX+wJFBx/7YmgoCCpX7++bNu2zeFn33//vVSvXl1Klixpel1fvHZq0KCBJCcnyx9//GH3pPj777/P/zk8x197Ij09XbKzs+Wvf/2rw8/mz58v8+fPl+XLl0vnzp1NretrPXH06FHJy8uTYcOGybBhwxx+Xq1aNRk+fPgtfSwt7PlrT1iJayf4a19wrriKc4Xn+WtP/FnVqlXzB20ZGRmyfft26dq1q1tr+VpP/FnZsmXl/vvvz//v9evXy+233y61atWyZH+Flb/2RFBQkDRo0ED++9//SlZWVv5HBotI/h/5uPOVCL7cE9f75ZdfpEiRIj7zrtBA4a898WecJ3zjPOFz3yk9Y8YMu/9+8803RUTkwQcfvOHtgoODpWvXrrJ06VLZs2ePw89PnjyZ/+/t27eX3377TZKSkvKzixcvqm+zv3jxoqSkpMipU6dcPobVq1dLRkaGR949bOa4rv31k2EY+dn3338vmzdvdmlfKSkpkp6e7nJtJ0+elPXr10uXLl1u+le4cJ8/98Tx48elTZs2EhQUJGvXrvXY90B1795dNm/eLGvXrnX4WUZGhuTk5IjI1d+BzWaT3Nzc/J+npaXJihUrXNpPamqqy3+t9NRTT8nixYtl5syZ8vDDD7t0G7jHn3vCKr7YEyg4/twTCQkJ8t///tduMH3gwAH56quvpFu3bje9vcYXr50SEhIkNzfX7vd15coVmTdvnjRt2lSqVKni0v7gGn/tiZ49e8ry5csd/rm2v+XLl0vTpk1vuMatHldB9ES9evXU46xbt65UrVpVli9fLv3793dpf3CNv/aElbh2gr/2BecKzhVW8deecGbs2LGSk5Nj+msVr/G1nnBm8eLF8t///leefvppCQryuZf5/Zo/90SPHj0kNzc3/+N7Ra5+0sTChQulTp06br2Jzhd74s/7vGbXrl2ycuXK/Nej4Tn+3BMazhPe43PvlD506JDEx8dLu3btZPPmzfLhhx9Kr1695O67777pbf/1r39JcnKyNG3aVAYMGCB16tSRM2fOyI4dO2T9+vVy5swZEREZMGCAvPXWW/L444/L9u3bpVKlSrJgwQJ1sLp161Zp2bKlJCYm3vRL069ZuHChhIWFuf1XFu4eV8eOHWXZsmXSpUsX6dChgxw6dEhmz54tderUkczMzJvup3bt2hIXF+fSl6aLXL1D5+Tk8NHdFvPnnmjXrp388ssvMnr0aNm0aZNs2rQp/2cVKlSQv//97+Z+Gf/fqFGjZOXKldKxY0fp27evNGzYUC5cuCA//vijJCUlSVpamkRGRkqHDh1k2rRp0q5dO+nVq5ecOHFCZsyYITExMbJ79+6b7qdVq1YiIg4fi3a96dOny8yZM+W+++6TYsWKyYcffmj38y5dukjx4sXdOlY48ueeOHfuXP5F27fffisiIm+99ZaUKVNGypQpI0OHDjX527jK13pCRGTBggVy+PBhuXjxooiIbNiwQSZNmiQiIo899phERUW5daxw5M89MXjwYHnnnXekQ4cOMnLkSAkNDZVp06ZJhQoVZMSIEW79PswcV0FdOzVt2lS6desmY8eOlRMnTkhMTIx88MEHkpaWJnPnznX7OKHz156oVauW079crlatmul3vblzXAXRE5GRkeqxXHu3260cJ3T+2hMiXDtx7WQdf+0LzhXTRYRzhRX8tSeu7X/Pnj3StGlTCQkJkRUrVsi6detk0qRJt/Td677UEyJXzwsTJ06UNm3aSEREhGzZskXmzZsn7dq1k+HDh7t9nND5c08MHDhQ3n33XRkyZIgcPHhQqlatmn+d8dlnn7n1+zBzXAXVEz169JCiRYtKbGyslC9fXvbt2ydz5syRYsWKyb/+9S+3jxM6f+4JzhM+dp4wfERiYqIhIsa+ffuMhIQEo2TJkkbZsmWNoUOHGpcuXbLbVkSMIUOGqOv8/vvvxpAhQ4wqVaoYoaGhRsWKFY1WrVoZc+bMsdvu8OHDRnx8vFGsWDEjMjLSGD58uLFmzRpDRIzk5OT87ZKTkw0RMRITE106jnPnzhlFihQxHn74YVPH74njysvLM15++WUjKirKCAsLM+655x5j1apVRp8+fYyoqCiHfV1/TCJixMXFuVxvs2bNjPLlyxs5OTku3wauC4SeEBGn/7hyX4uKijI6dOig/uz8+fPG2LFjjZiYGOO2224zIiMjjdjYWOPVV181srKy8rebO3eucccddxhhYWFGrVq1jHnz5uX/bq/fV58+fRyy63tH06dPnxse66FDh266Bm4uEHri0KFDTu8nrtzX/KUnDMMw4uLinB7rn39/cF8g9IRhGMavv/5qJCQkGKVKlTJKlChhdOzY0fjpp59cuq0/XTtdunTJGDlypFGxYkUjLCzMaNy4sbFmzRqXbgvXBEpPXO9GtZrZ1td64npxcXFG3bp13botdIHQE1w7ce3kaYHQFxrOFXBXIPTEqlWrjCZNmhglS5Y0ihUrZjRr1sxYsmSJy78Df+mJn3/+2WjTpo0RGRmZf06aMmWKceXKFZePFTcXCD1xbf99+vQxwsPDjbCwMKNp06YuP//0l554/fXXjSZNmhjh4eFGSEiIUalSJePRRx91+fUEuCYQeoLzhG+dJ2yG8af3jHvRhAkT5J///KecPHlSIiMjvV0O4HX0BGCPngDs0ROAPXoCsEdPAI7oC8AePQHYoycAe/QEPM03PkQcAAAAAAAAAAAAABCQGEoDAAAAAAAAAAAAACzDUBoAAAAAAAAAAAAAYBmf+U5pAAAAAAAAAAAAAEDg4Z3SAAAAAAAAAAAAAADLMJQGAAAAAAAAAAAAAFiGoTQAAAAAAAAAAAAAwDIhrm5os9msrAMwzdtfh05PwNfQE4A9egKwR08A9ugJwB49AdijJwB79ARgj54A7LnSE7xTGgAAAAAAAAAAAABgGYbSAAAAAAAAAAAAAADLMJQGAAAAAAAAAAAAAFiGoTQAAAAAAAAAAAAAwDIMpQEAAAAAAAAAAAAAlmEoDQAAAAAAAAAAAACwDENpAAAAAAAAAAAAAIBlGEoDAAAAAAAAAAAAACzDUBoAAAAAAAAAAAAAYBmG0gAAAAAAAAAAAAAAyzCUBgAAAAAAAAAAAABYhqE0AAAAAAAAAAAAAMAyDKUBAAAAAAAAAAAAAJZhKA0AAAAAAAAAAAAAsAxDaQAAAAAAAAAAAACAZRhKAwAAAAAAAAAAAAAsE+LtAgD4vpEjR6p50aJF1fyuu+5S84SEBJf3OWvWLDXfvHmzmi9YsMDltQEAAAAAAAAAAFBweKc0AAAAAAAAAAAAAMAyDKUBAAAAAAAAAAAAAJZhKA0AAAAAAAAAAAAAsAxDaQAAAAAAAAAAAACAZRhKAwAAAAAAAAAAAAAsYzMMw3BpQ5vN6loAU1y861omEHti8eLFap6QkFDAlTiXmpqq5q1bt1bz9PR0K8vxKfRE4VSzZk01T0lJUfPhw4er+ZtvvumxmnwFPeG7ihcvruZTp051yAYOHKhuu337djXv1q2bmh8+fNjF6gIXPQHYoycAe/QEYI+eAOzRE/izsmXLqnnVqlU9sr6z5/DPPPOMmu/Zs8chO3jwoLrtrl273C/sT+gJwJ4rPcE7pQEAAAAAAAAAAAAAlmEoDQAAAAAAAAAAAACwDENpAAAAAAAAAAAAAIBlGEoDAAAAAAAAAAAAACwT4u0CABS8xYsXq3lCQoJH1k9JSVHztWvXOmTVq1dXt+3UqZOa16hRQ8179+6t5lOmTFFzIFDcc889ap6Xl6fmR44csbIcwCWVKlVS8wEDBjhkzu7LDRs2VPOOHTuq+YwZM1ysDrh19957r5ovW7ZMzaOjoy2sxjPatGmj5vv371fzX3/91cpyALc5e56xcuVKNR86dKiaz549W81zc3PdKwwBqXz58mq+ZMkSNf/uu+/UfM6cOWqelpbmVl2+oHTp0mr+wAMPqPmaNWscsuzsbI/WBACFWYcOHdQ8Pj5ezVu0aKHmMTExHqnn4MGDah4VFaXmYWFhLq8dHBzsVk0Abh3vlAYAAAAAAAAAAAAAWIahNAAAAAAAAAAAAADAMgylAQAAAAAAAAAAAACWYSgNAAAAAAAAAAAAALAMQ2kAAAAAAAAAAAAAgGVCvF0AAOs0atRIzbt06WJqnb1796p5fHy8mp86dUrNMzMzHbLbbrtN3XbLli1qfvfdd6t5RESEmgOBrkGDBmp+4cIFNV++fLmF1QD2ypUrp+YffPBBAVcCFKy2bduqeVhYWAFX4jmdOnVS8379+ql5z549rSwHuClnzw9mzpxpap233npLzd977z01v3Tpkqn1ERjKli2r5s6eS5cuXVrNf//9dzVPS0tzqy5f4OxYt2/frubOrh8bNmzokP3888/uFwa/UKpUKTWfMmWKmterV88ha926tbptdna2+4UBPqZGjRpqPmTIEIdswIAB6rZFixZVc5vN5n5ht6BmzZpe2S8Aa/FOaQAAAAAAAAAAAACAZRhKAwAAAAAAAAAAAAAsw1AaAAAAAAAAAAAAAGAZhtIAAAAAAAAAAAAAAMswlAYAAAAAAAAAAAAAWCbE2wW4IyEhQc0HDBig5r/99puaX758Wc0XLlyo5sePH1fzn3/+Wc0Bb6tUqZKa22w2Nd+7d6+at23bVs2PHTvmXmF/MmLECDWvU6eOqXU+//zzW64F8GX16tVT86FDh6r5ggULrCwHsDNs2DA179y5s5o3adLEsloeeOABNQ8K0v8Wc9euXWq+YcMGj9WEwBUSoj+dat++fQFXYr3t27er+bPPPqvmxYsXV/MLFy54rCbgRpydD26//XZT63z88cdq7uz1BAS2yMhINV+8eLGah4eHq/nMmTPV/KmnnnKvMB82fvx4Na9WrZqaDxw4UM157S2w9e7dW80nT56s5lWqVHF57VKlSqn56dOnXV4D8HXOrm+GDx9ewJWYl5KSoubOXqcGbkVMTIxD5uz6rkuXLmreokULNc/Ly1Pz2bNnq/m3336r5oF+zcM7pQEAAAAAAAAAAAAAlmEoDQAAAAAAAAAAAACwDENpAAAAAAAAAAAAAIBlGEoDAAAAAAAAAAAAACzDUBoAAAAAAAAAAAAAYJkQbxfgjldeeUXNo6OjPbL+wIED1fz8+fNqvnfvXo/s1xuOHDmi5s5+x9u2bbOyHHjYZ599puYxMTFq7uw+fubMGY/VdL2ePXuqeWhoqGX7BPxRrVq11Lx48eJqvnjxYivLAez8+9//VvO8vLwCrkTk4YcfNpUfPnxYzXv06KHm27dvd68wBKSWLVuq+X333afmzq6x/UHZsmXVvE6dOmperFgxNb9w4YLHagJERMLCwtT8+eef98j6CxYsUHPDMDyyPvzLvffeq+YtWrQwtc7EiRM9UI1vqVu3rpqPGDFCzZcvX67mPI8JbLfffruaT58+Xc0jIiLU3Mxj8JtvvqnmQ4cOVXMrXwND4RUZGanmw4cPV/Nvv/1WzdesWaPmV65cUfNz5845ZM6ux529vrRu3To137Nnj5p///33av7DDz+o+aVLl9Sc5w1wRb169dTc2WO89tqQs/70lKZNm6p5Tk6Omh84cEDNN23apObOHkeysrJcqK7g8U5pAAAAAAAAAAAAAIBlGEoDAAAAAAAAAAAAACzDUBoAAAAAAAAAAAAAYBmG0gAAAAAAAAAAAAAAyzCUBgAAAAAAAAAAAABYJsTbBbhjwIABan7XXXep+f79+9W8du3aan7vvfeqeYsWLdS8WbNmav7rr786ZFWqVFG3NSsnJ0fNT548qeaVKlUytX56erqab9u2zdQ68E2HDx/2yn5HjRrlkNWsWdPUGt9//72pHAgUo0ePVnNn/czjNaywevVqNQ8KKvi/czx9+rSaZ2ZmqnlUVJSaV6tWTc23bt2q5sHBwS5Uh0BTr149Nf/444/VPDU1Vc1ffvllj9VU0B566CFvlwCo6tevr+YNGzY0tY6z59j/+c9/TNcE/1e+fHk179q1q6l1+vfvr+bOXrvxB3Xr1lXz9evXm1pn+fLlan7+/HnTNcF/jBw5Us3Dw8Mt22ePHj3UvF27dmo+efJkNX/zzTfVPCsry73CEJCKFy+u5uvWrVPzu+++W827dOliar9btmxRc23OkZaWpm5btWpVNT9y5Iia5+XluVYcYIKzGd+QIUPU3NljfKlSpVze59GjR9V848aNan7o0CE1d/ba7fbt29W8SZMmau7snNi+fXs137Vrl5rPnj1bzb2Nd0oDAAAAAAAAAAAAACzDUBoAAAAAAAAAAAAAYBmG0gAAAAAAAAAAAAAAyzCUBgAAAAAAAAAAAABYhqE0AAAAAAAAAAAAAMAyId4uwB1ffvmlqdyZNWvWmNq+bNmyat6gQQM13759u0PWuHFjU/t05vLly2p+8OBBNd+/f7+ah4eHq3lqaqp7hQEi0rFjRzWfOHGiQ3bbbbep2544cULNx44dq+YXL150sTrAt0VHR6t5o0aN1NzZ4/6FCxc8VRIKobi4ODW/88471TwvL89Ubsbs2bPVfN26dWp+7tw5Nf/b3/6m5s8//7ypev7nf/5HzWfNmmVqHfiX8ePHq3nx4sXVvF27dmqemZnpsZqs4uz5gbPHBU/0OXArunbt6pF1nJ1XUDi99tprav7oo4+qufb6j4jIJ5984rGafEXz5s3VvEKFCmr+/vvvq/mHH37oqZLgg6KiotT8H//4h6l1du/erea///67mrdu3drltUuXLq3mI0eOVPOFCxeq+fHjx13eJwKHs9czP/roIzW/++671fzll19W8/Xr17tX2HXS0tJc3jY9Pd0j+wRc8fbbb6t5ly5d1DwyMtLU+s5mhT/++KNDNm7cOHVbZzM4Z2JjY9Xc2etI7733npo7mzc6O/fNmDFDzZcuXeqQnTx5Ut22IPFOaQAAAAAAAAAAAACAZRhKAwAAAAAAAAAAAAAsw1AaAAAAAAAAAAAAAGAZhtIAAAAAAAAAAAAAAMswlAYAAAAAAAAAAAAAWCbE2wX4k7Nnz6p5cnKyy2t8+eWXnipH1bVrVzUvW7asmv/4449qvnjxYo/VhMKnUaNGan7bbbe5vIaz++A333zjVk2Av4iLizO1/cmTJy2qBIVBdHS0mi9atEjNIyMjPbLfw4cPq/nSpUsdsn/+85/qthcvXvTIPp988kk1L1eunJq/8soral6kSBE1f+utt9Q8OztbzeFdCQkJat6+fXs1//nnn9V827ZtHqupoD3//PNqnpeXp+Zff/21mmdkZHioIuDGHnjgAVPbZ2Vlqbmz+z4KJ8Mw1NzZY+Fvv/2m5s7ub76kaNGiaj5u3Dg1Hzx4sJo7+53169fPvcLg1xo0aKDmJUuWVPONGzequbPnx86uvR955BGHzNl9uUaNGmpesWJFNf/000/V/MEHH1TzM2fOqDn8S4kSJdR87Nixat6xY0c1P3XqlJq/+uqram72+S7gbc4el0ePHq3mTzzxhJrbbDY1d/b656xZs9R86tSpan7hwgU194SIiAg1Dw4OVvMJEyao+Zo1a9Q8KirKrbp8De+UBgAAAAAAAAAAAABYhqE0AAAAAAAAAAAAAMAyDKUBAAAAAAAAAAAAAJZhKA0AAAAAAAAAAAAAsAxDaQAAAAAAAAAAAACAZUK8XQDcU758eTWfOXOmmgcF6X9/MHHiRDU/c+aMe4WhUFmxYoWat2nTxuU15s+fr+bjx493pyTA79WvX9/U9q+88opFlaAwCAnRLwUjIyM9sv4333yj5j179lTzU6dOeWS/msOHD6v5lClT1HzatGlqXqxYMTV31osrV65U89TUVDWHd3Xr1k3Nnf1/d3bt7Q+io6PVvHfv3mqem5ur5pMmTVLz7Oxst+oCbiQ2Ntal7EYuXLig5jt37nSnJEBERDp06KDm69atU/OMjAw1nzVrlqdKchAXF6fmLVq0UPNmzZqZWj8pKclsSQhgYWFham4Yhpr/+9//NrX+5cuX1XzevHkOmbPru+rVq5va58WLF9U8KyvL1DrwL507d1bzMWPGqHl6erqaN2/eXM3PnTvnVl2Ar3F2PTFq1Cg1t9lsan706FE179q1q5pv3br15sW5KTg4WM2rVKmi5s7mHKtXr1bzsmXLmqrH2e9swYIFau7setPbeKc0AAAAAAAAAAAAAMAyDKUBAAAAAAAAAAAAAJZhKA0AAAAAAAAAAAAAsAxDaQAAAAAAAAAAAACAZRhKAwAAAAAAAAAAAAAsE+LtAuCeIUOGqHm5cuXU/OzZs2p+4MABj9WEwFWpUiU1j42NVfOwsDA1P3XqlEM2adIkddvMzEwXqwP8V7NmzRyyf/zjH+q2P/zwg5p/8cUXHq0JcMe2bdvUvF+/fmqunQ+8ZeXKlWreu3dvNW/cuLGV5aCAlC5dWs21x+UbmTVrlifK8Yonn3xSzSMjI9V8//79ap6cnOyxmoCb8cRjsD/3LQrO66+/ruYtW7ZU88qVK6v5Aw88oOY2m03N4+PjXajOPc72aRiGqXV++eUXNR83bpzpmhC4HnnkEVPbd+jQQc1XrFhxy7U0atToltcQEdmyZYua8/pVYHP22qczzl67OXLkiCfKAXxWcHCwmufm5ppaJycnR82bNm2q5gkJCWpeq1Ytl/d56dIlNa9du7ap3NlrXRUqVHC5lhv5/fff1dzZfCU7O9sj+/U03ikNAAAAAAAAAAAAALAMQ2kAAAAAAAAAAAAAgGUYSgMAAAAAAAAAAAAALMNQGgAAAAAAAAAAAABgmRBvF4Ab++tf/6rmY8aMMbVO586d1XzPnj1mS0IhtHTpUjWPiIgwtc6HH37okKWmprpVExAIWrdu7ZCFh4er265Zs0bNL1++7NGaABGRoCBzf7fYtGlTiyqxns1mU3NnvwOzv5sJEyao+WOPPWZqHXhWWFiYmv/lL39R848//tjKcryiRo0aprbneQN8QaNGjVzeNiMjQ81nzZrloWoQyLZv367md911l5o3aNBAzdu1a6fmo0aNUvOTJ0+q+QcffKDmZixYsEDNd+3aZWqd7777Ts15bo8/c3btFB8fr+aNGzdW81q1aql5/fr11bxLly4OWdmyZdVtnZ0nnG0/YMAANXfWW/v27VNz+JeEhART2zt73E9MTFTzTz/9VM137txpar+At3311VdqnpycrObaa6IiIlWrVlXzN954Q80Nw3Chuv+Tm5vrkAUHB5taw5kKFSqY2j4vL0/Nly9frubDhg1T82PHjpnar7fxTmkAAAAAAAAAAAAAgGUYSgMAAAAAAAAAAAAALMNQGgAAAAAAAAAAAABgGYbSAAAAAAAAAAAAAADLMJQGAAAAAAAAAAAAAFjGZhiG4dKGNpvVtUAxefJkNR87dqyaf/nll2revn17Nc/OznavMB/g4l3XMoHYE/Hx8Wq+ZMkSNQ8NDVXzr7/+Ws0feughhywzM9O14nBT9IT/+eSTTxyyrl27qts6y5cvX+7RmgIJPXFzr776qpoPHz7c1DrOzgf+4KmnnlLzadOmqXlQkP43nXl5eWpeq1YtNU9NTXWhOs+iJ/5P0aJF1Xzjxo1q7uw+3rJlSzU/c+aMe4VZoHz58mp+7NgxU+sMGzZMzWfMmGG6Jl9BT/iu+++/X82/+eYbh8zZ4/Lhw4fVPDo62u26Ah09EdiqV6+u5j///LOa79y5U83btm2r5idPnnSrLl9GT7gvPDxczZ3d30qXLq3mzn4HZv7frF+/Xs2HDBmi5qtWrVLzO+64Q83feecdNR80aJAL1fmXwtgTzo7Z2fM/s5ytM3v2bDXfsmWLmletWlXNtZ7bu3evi9VdVbduXTXfvHmzmh85csTU+v6sMPaEp5QpU0bNx4wZo+Z//etf1fz06dNqnp6eruZhYWEO2d13361u26RJEzX3FGd9Pm7cODXPyMiwsBrPcKUneKc0AAAAAAAAAAAAAMAyDKUBAAAAAAAAAAAAAJZhKA0AAAAAAAAAAAAAsAxDaQAAAAAAAAAAAACAZRhKAwAAAAAAAAAAAAAsE+LtAnBV0aJF1bxdu3ZqnpWVpeaJiYlqnp2d7V5hCEgRERFqPm7cODUPDQ01tf7OnTvVPDMz09Q6QKCoWLGimjdv3twhO3DggLrt8uXLPVoTICLSqVMnb5fgceXKlVPzOnXqqLmzc59ZJ0+eVHOuwXzTpUuX1Dw1NVXNu3btquaff/65mk+bNs29wlxQr149Na9evbqaR0dHq7lhGKb2m5eXZ2p74FY4e74SFOT639V/8cUXnioHCAgvvviimjs7Hzz33HNq7uyaB/izM2fOqHn37t3VPCkpSc1Lly5tar9vvvmmQ+bsvnz58mU1X7ZsmZqPGTNGzdu2bavmNWrUUHNn15vwTa+++qqaP/vssx5Z39m1zeDBg03l3uDsfPD111+rec+ePS2sBv4mIyNDzZ091lpp/vz5at6kSRNT65w/f17NnT1evP/++2qem5trar/+hndKAwAAAAAAAAAAAAAsw1AaAAAAAAAAAAAAAGAZhtIAAAAAAAAAAAAAAMswlAYAAAAAAAAAAAAAWIahNAAAAAAAAAAAAADAMiHeLgBXjRo1Ss3vueceNV+zZo2af/fddx6rCYFrxIgRat64cWNT66xYsULNExMTzZYEBLS+ffuqefny5R2y//znPxZXAwS2559/Xs2HDBnikfXT0tLUvE+fPmqenp7ukf2iYDi7hrHZbGreoUMHNf/44489VtP1Tp06peaGYah5ZGSkR/b7/vvve2QdwBUJCQkub5uRkaHmb7/9toeqAfxLt27d1Pzxxx9X8/Pnz6v56dOnPVYTcM369evV3Nnjfq9evdTc2WP/iy++6JBdvnzZteL+v5deeknNa9eurebx8fEu1yLi/HkDfNOYMWPUfPHixWr+0UcfqXlIiD6GqVKlipoHBfn+ewnLlSun5s76efz48Wo+adIkj9UE3Mzo0aMdsp49e3pk7UGDBqm5la8P+CPff3QDAAAAAAAAAAAAAPgthtIAAAAAAAAAAAAAAMswlAYAAAAAAAAAAAAAWIahNAAAAAAAAAAAAADAMgylAQAAAAAAAAAAAACWCfF2AYVNhw4d1PyFF15Q8z/++EPNJ06c6LGaUPg8++yzHlln6NChap6ZmemR9YFAERUV5fK2Z8+etbASIHCsXr1aze+8805L97tv3z4137Rpk6X7RcFISUlR8+7du6t5gwYN1DwmJsZTJTlISkoytf0HH3yg5r179za1zqVLl0xtD7ji9ttvV/NevXq5vMaRI0fUfNu2bW7VBPi7Bx980NT2q1atUvMdO3Z4ohzAJevXrzeVW8nZNc/ixYvVPD4+Xs1btmyp5uHh4Wp+5swZF6pDQcvNzVVzZ9cZNWvWNLV+q1at1Dw0NFTNJ0yYoOaNGzc2tV8r2Ww2NW/YsGEBV4LC7IknnlDz8ePHO2QhIebGpHv37lXzZcuWmVqnsOKd0gAAAAAAAAAAAAAAyzCUBgAAAAAAAAAAAABYhqE0AAAAAAAAAAAAAMAyDKUBAAAAAAAAAAAAAJZhKA0AAAAAAAAAAAAAsEyItwsIZBEREQ7ZG2+8oW4bHBys5qtXr1bzLVu2uF8Y4CHh4eFqnp2dbdk+z507Z2qfoaGhal66dGlT+y1TpoyaP/vss6bW0eTm5qr5c889p+YXL1685X2iYHXs2NHlbT/77DMLKwHs2Ww2NQ8KMvd3iw8++KCp7efMmaPmlStXdnkNZzXm5eWZqsWsTp06Wbo+/MvOnTtN5d7wyy+/eGSdevXqqfmePXs8sj4Kp9jYWDU3cx5asWKFh6oBAoOz67ILFy6o+WuvvWZlOUDAWLJkiZrHx8ereY8ePdR86NChaj5x4kT3CoNf+/LLL01t36BBAzVv3Lixmufk5Dhk8+bNU7d955131Pzpp59W8169eqk5UJCaNGmi5s6ub0qUKOHy2pmZmWo+aNAgNb9y5YrLaxdmvFMaAAAAAAAAAAAAAGAZhtIAAAAAAAAAAAAAAMswlAYAAAAAAAAAAAAAWIahNAAAAAAAAAAAAADAMgylAQAAAAAAAAAAAACWCfF2AYEgODhYzdesWeOQVatWTd02NTVVzV944QX3CwMstnv37gLf5yeffKLmx44dU/MKFSqoeY8ePTxWk1WOHz+u5pMnTy7gSuCq+++/X80rVqxYwJUArpk1a5aav/LKK6bWWbVqlZrn5eWZWsfs9latISIye/Zsj6wDeJvNZjOVO7Nnzx5PlAPYiYiIMLX9qVOnHLLXX3/dU+UAfmfQoEEOmbPnwCdOnFDzHTt2eLQmIFA5e57h7LnTQw89pOaJiYlqvmjRIjU/ePCgC9WhsFi3bp2aO3utMCTEcfwzYMAAdduYmBg1b9GihWvF3cSRI0c8sg7wZ506dVLzkiVLurzGhQsX1Dw+Pl7Nv/32W5fXhiPeKQ0AAAAAAAAAAAAAsAxDaQAAAAAAAAAAAACAZRhKAwAAAAAAAAAAAAAsw1AaAAAAAAAAAAAAAGAZhtIAAAAAAAAAAAAAAMuEeLuAQFCjRg01b9iwoctrPPvss2qemprqVk3AjaxevVrNH3rooQKuxLxu3bpZun5OTo6a5+XlmVpn5cqVDtm2bdtMrbFx40ZT28P7unTpoubBwcFq/sMPPzhkGzZs8GhNwI0sW7ZMzUeNGqXm5cqVs7Icjzh58qSa79+/X82ffPJJNT927JjHagK8yTAMUzlQkNq2bWtq+/T0dIfs3LlznioH8DuDBg1yyJw9vn/++eem1i5ZsqSaly1bVs21/gQKg507d6r5iy++qOZTp05V85dfflnNH3vsMTW/dOnSzYtDwHH2vHbJkiVq3r17d5fXbtmypalacnNz1dzZ+WbMmDGm1gf+zNl1yejRo2957YULF6r5119/fctrwxHvlAYAAAAAAAAAAAAAWIahNAAAAAAAAAAAAADAMgylAQAAAAAAAAAAAACWYSgNAAAAAAAAAAAAALAMQ2kAAAAAAAAAAAAAgGVCvF2AP4mKilLzdevWubzGqFGj1HzVqlVu1QS44+GHH1bz0aNHq3loaKhH9lu3bl2HrEePHh5Z+7333lPztLQ0U+ssXbpUzVNSUsyWhABWrFgxNW/fvr2pdZKSkhyy3Nxct2oC3HH48GE179mzp5p37txZzYcPH+6pkm7Z5MmT1XzGjBkFXAngG4oUKWJq+0uXLllUCQozZ88natSoYWqdy5cvO2TZ2dlu1QQUNs6eZ/Tu3VvNn3nmGTXfu3evmvfp08e9woAANX/+fDUfOHCgmjt7rW7ixIlqvnv3bvcKg19zdq3+9NNPq3mJEiUcskaNGqnbli9fXs2dvba6YMECNZ8wYYKaA67Q7rMiIvv27VNzs3ML7bHTWf/AGrxTGgAAAAAAAAAAAABgGYbSAAAAAAAAAAAAAADLMJQGAAAAAAAAAAAAAFiGoTQAAAAAAAAAAAAAwDIMpQEAAAAAAAAAAAAAlrEZhmG4tKHNZnUtPm/y5MlqPnbsWJfXaNKkiZpv27bNrZoKMxfvupahJ+Br6ImCExoaqubffPONmp84cULNe/Xq5ZBdvHjR/cJgh54oOO3atVPzJ598Us07deqk5itXrnTI5syZo27r7Pe7b98+NU9PT1fzwoSeKJyOHz+u5iEhIWr+0ksvqfnrr7/usZp8BT1RcIKDg9X83XffVfO+ffuq+fz58x2yPn36uF0X7NET/mfnzp0OWf369dVtnf1+nf1/nzt3rpo7O0/8+uuvau7P6AlYoWrVqmqelpam5h9//LGa9+7d21MluYyeCAyPPfaYmjdr1kzN//nPf6q5s9e6ChN6wvPi4+PV/NNPP1Vzs/8PWrVq5ZAlJyebWgPOufL/g3dKAwAAAAAAAAAAAAAsw1AaAAAAAAAAAAAAAGAZhtIAAAAAAAAAAAAAAMswlAYAAAAAAAAAAAAAWMZmuPhN4IH4penO3H///Wq+evVqNS9RooTLazdp0kTNt23b5vIauMrsl9h7WmHqCfgHegKwR08A9uiJwumzzz5T82nTpql5cnKyleX4FHrC+ypXrqzmkyZNUvPt27c7ZDNmzPBoTYUZPeF/tNevJk6cqG67YcMGNZ81a5aanz17Vs2zsrJcrM7/0RMoSOvWrVPz++67T82bNm3qkO3bt8+jNV2PngDs0ROet2vXLjWvX7++qXWmTp2q5s8995zpmuA6V3qCd0oDAAAAAAAAAAAAACzDUBoAAAAAAAAAAAAAYBmG0gAAAAAAAAAAAAAAyzCUBgAAAAAAAAAAAABYhqE0AAAAAAAAAAAAAMAyId4uwBc1b95czUuUKGFqndTUVIcsMzPTrZoAAAAAwKxOnTp5uwTAqd9++03N+/XrV8CVAP5p06ZNDtnf/vY3L1QC4FYlJCSo+a5du9Q8JibGIdu3b59HawKAghYeHq7mNptNzU+cOKHm06dP91RJ8DDeKQ0AAAAAAAAAAAAAsAxDaQAAAAAAAAAAAACAZRhKAwAAAAAAAAAAAAAsw1AaAAAAAAAAAAAAAGAZhtIAAAAAAAAAAAAAAMuEeLuAQLBr1y41b9WqlUN25swZq8sBAAAAAAAAAPiJP/74Q82rVatWwJUAgPdMmzbNVP7SSy+p+bFjxzxWEzyLd0oDAAAAAAAAAAAAACzDUBoAAAAAAAAAAAAAYBmG0gAAAAAAAAAAAAAAyzCUBgAAAAAAAAAAAABYhqE0AAAAAAAAAAAAAMAyNsMwDJc2tNmsrgUwxcW7rmXoCfgaegKwR08A9ugJwB49AdijJwB79ARgj54A7NETgD1XeoJ3SgMAAAAAAAAAAAAALMNQGgAAAAAAAAAAAABgGYbSAAAAAAAAAAAAAADLMJQGAAAAAAAAAAAAAFiGoTQAAAAAAAAAAAAAwDI2wzAMbxcBAAAAAAAAAAAAAAhMvFMaAAAAAAAAAAAAAGAZhtIAAAAAAAAAAAAAAMswlAYAAAAAAAAAAAAAWIahNAAAAAAAAAAAAADAMgylAQAAAAAAAAAAAACWYSgNAAAAAAAAAAAAALAMQ2kAAAAAAAAAAAAAgGUYSgMAAAAAAAAAAAAALMNQGgAAAAAAAAAAAABgmf8HXis6KIvshM8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(25.0, 25.0))\n",
        "for i in range(10):\n",
        "    img = imgs[i]\n",
        "\n",
        "    plt.subplot(1, 10, i + 1)\n",
        "    plt.title(\n",
        "        \"pred: \" + str(digits[i]) + \" real: \" + str(labels[i].numpy())\n",
        "    )  # predicted and real values\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.numpy(), cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf0ARzLS6P8W"
      },
      "source": [
        "## Сохранение и загрузка весов модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ-68zgf6P8W"
      },
      "source": [
        "Обычно обучение модели является достаточно затратным процессом с точки зрения вычислительных ресурсов. Поэтому, однажды обучив сеть, разумно будет сохранить ее для последующего использования. Рассмотрим варианты, как это можно сделать в PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XiNQr3Y6P8W"
      },
      "source": [
        "Модели PyTorch хранят обучаемые параметры во внутреннем словаре состояния, который называется `state_dict`. Их можно сохранить с помощью метода `torch.save`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUeh5qFG6P8X"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model_weights.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN-ju_BH6P8X"
      },
      "source": [
        "Для того, чтобы загрузить веса модели, сперва необходимо создать экземпляр такой модели, а затем загрузить параметры с помощью метода `load_state_dict()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7cgRG906P8X",
        "outputId": "2140538a-cbbf-4985-a69b-b865d2def67d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (layers_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auvfX1Vx6P8X"
      },
      "source": [
        "<font size=\"6\">Ссылки:</font>\n",
        "\n",
        "[StatSoft. Радиальная базисная функция](http://statsoft.ru/home/textbook/modules/stneunet.html#radial)\n",
        "\n",
        "[Understanding Loss Functions in Machine Learning](https://www.section.io/engineering-education/understanding-loss-functions-in-machine-learning/)\n",
        "\n",
        "[Understanding Categorical Cross-Entropy Loss, Binary Cross-Entropy Loss, Softmax Loss, Logistic Loss, Focal Loss and all those confusing names](https://gombru.github.io/2018/05/23/cross_entropy_loss/)\n",
        "\n",
        "[Объясненные современные функции активации: GELU, SELU, ELU, ReLU и другие](https://www.kdnuggets.com/2022/06/activation-functions-work-deep-learning.html)\n",
        "\n",
        "Видеолекции курса А. Г. Дьяконова \"Глубокое обучение\" на тему PyTorch: [часть 1](https://www.youtube.com/watch?v=tDJnwc8Hioc), [часть 2](https://www.youtube.com/watch?v=c3y--ydWku0)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}